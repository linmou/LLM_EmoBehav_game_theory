# Fantom memory benchmark sanity config
# Use with: python -m emotion_memory_experiments.memory_experiment_series_runner \
#             --config config/fantom_memory_sanity.yaml --dry-run

experiment_name: "fantom_simple_qwen2.5"
description: "Config for simple Fantom tasks (binary + 2-choice)"
version: "1.0.0"

models:
  #- "/data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct"
    #- "/data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-1.5B-Instruct"
    #- "/data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-3B-Instruct"
  - "/data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-7B-Instruct"

benchmarks:
  - name: "fantom"
    task_type: "short_answerability_binary_inaccessible"
    base_data_dir: "data/fantom"
      # - name: "fantom"
      #task_type: "short_belief_choice_inaccessible"
      #base_data_dir: "data/fantom"

emotions: ["anger", "happiness", "sadness", "surprise","fear", "disgust"]
intensities: [1.5]

loading_config:
  model_path: null
  gpu_memory_utilization: 0.90
  tensor_parallel_size: null
  max_model_len: 4096
  enforce_eager: true
  quantization: null
  trust_remote_code: true
  dtype: "float16"
  seed: 42
  disable_custom_all_reduce: false
  additional_vllm_kwargs: {}

repe_eng_config:
  direction_method: "pca"

generation_config:
  temperature: 0.1
  max_new_tokens: 400
  do_sample: false
  top_p: 0.9
  repetition_penalty: 1.0
  top_k: -1
  min_p: 0.0
  presence_penalty: 0.0
  frequency_penalty: 0.0
  enable_thinking: false

batch_size: 600
max_evaluation_workers: 1
pipeline_queue_size: 1

output_dir: "results/fantom_qwen2.5"

run_sanity_check: false


# Test configuration with downloaded data
experiment_name: "test_downloaded_data"
description: "Test configuration using downloaded benchmark data"
version: "1.0.0"

model:
  model_path: "../huggingface_models/Qwen/Qwen2.5-0.5B-Instruct"  

# vLLM loading configuration
loading_config:
  # model_path: "../huggingface_models/Qwen/Qwen2.5-0.5B-Instruct"  # Optional: overrides model.model_path if specified
  gpu_memory_utilization: 0.90  # Fraction of GPU memory to use
  tensor_parallel_size: null  # Auto-detect based on model size
  max_model_len: 32768  # Maximum sequence length
  enforce_eager: true  # Use eager mode (disable CUDA graphs)
  quantization: null  # Set to 'awq' for AWQ quantized models
  trust_remote_code: true  # Allow loading custom model code
  dtype: "float16"  # Model dtype: 'float16', 'bfloat16', 'float32'
  seed: 42  # Random seed for reproducibility
  disable_custom_all_reduce: false  # Disable custom all-reduce kernel
  
  # Context truncation settings
  enable_auto_truncation: true  # Automatically truncate long contexts
  truncation_strategy: "right"  # Strategy: "right" or "left"
  preserve_ratio: 0.95  # Use 95% of max_model_len for context

# Emotion manipulation settings
emotions:
  target_emotions: ["anger", "happiness"]
  include_neutral: true
  intensities: [1.5]

# Benchmark configuration using downloaded data
benchmarks:
  # InfiniteBench Passkey Retrieval (downloaded)
  infinitebench_passkey:
    name: "longbench"
    task_type: "narrativeqa"
    data_path: "data/memory_benchmarks/longbench_narrativeqa.jsonl"
    evaluation_method: "get_score_one_passkey"
    sample_limit: 500

# Generation parameters (extended)
generation:
  temperature: 0.1
  max_new_tokens: 50
  do_sample: false
  top_p: 0.9
  repetition_penalty: 1.0
  top_k: -1  # -1 means no top_k filtering
  min_p: 0.0  # Minimum probability threshold
  presence_penalty: 0.0  # Penalize tokens based on presence
  frequency_penalty: 0.0  # Penalize tokens based on frequency
  enable_thinking: false  # Enable Qwen thinking mode

# Execution settings
execution:
  batch_size: 4
  max_evaluation_workers: 2

# Output configuration
output:
  results_dir: "results/test_downloaded"
  save_intermediate: true
  formats: ["csv"]
  log_level: "INFO"

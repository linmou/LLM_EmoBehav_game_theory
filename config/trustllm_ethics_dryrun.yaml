models:
  - /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct

benchmarks:
  - name: trustllm_ethics
    task_type: social_norm
    data_path: data/TrustLLM/tmp/social_norm_sample.json
    sample_limit: 3
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

emotions: [anger]
intensities: [1.0]

output_dir: results/memory_experiments
batch_size: 1

# If you want a minimal real run instead of dry-run, set sanity_check: true
# and invoke without --dry-run. You can also set sanity_check_limit.
sanity_check: true
sanity_check_limit: 3

# minimal gen config; model generation is not executed in dry-run mode
generation_config:
  temperature: 0.0
  max_new_tokens: 16
  do_sample: false

loading_config:
  model_path: /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct
  gpu_memory_utilization: 0.90
  tensor_parallel_size: 1
  max_model_len: 8192
  enforce_eager: true
  trust_remote_code: true
  dtype: float16
  seed: 42
  disable_custom_all_reduce: false
  additional_vllm_kwargs: {}

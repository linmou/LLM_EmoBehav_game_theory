experiment:
  name: "Prisoners_Dilemma_New_Template_hook"
  game:
    name: "Prisoners_Dilemma"  # or "Prisoners_Dilemma"
    
  data:
    generate: false  # Set to false to skip data generation
    num_scenarios: 36
    batch_size: 4
  
  llm:
    model_name: 'meta-llama/Llama-3.1-8B-Instruct' 
    generation_config:
      temperature: 0.7
      do_sample: true
      top_p: 0.95
      max_new_tokens: 440

  system_message_template: "Remember you are Alice. What is your option? Choose one option shown above."
  
  repeat: 5

  emotions:
    - "anger"

  intensity:
    - 1.5
  
  # Use string 'auto_batch_size' to enable automatic batch size detection
  batch_size: 'auto_batch_size'
  batch_size_safety_margin: 0.9  # Percentage of GPU memory to target (0.9 = 90%)
  
  # Set to true to run a sanity check instead of the full experiment
  run_sanity_check: false
    
  output:
    base_dir: "results/RepEng"
    save_plots: true
    plot_format: "png" 
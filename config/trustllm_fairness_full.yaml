# Full TrustLLM Fairness run (stereotype_recognition, stereotype_agreement,
# stereotype_query, disparagement, preference)
# Edit the data_path values to point to your local TrustLLM fairness JSON files.
# Typical filenames (from TrustLLM docs):
#   stereotype_recognition.json
#   stereotype_agreement.json
#   stereotype_query_test.json
#   disparagement.json
#   preference.json

models:
  - /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct

benchmarks:
  - name: trustllm_fairness
    task_type: stereotype_recognition
    data_path: /path/to/TrustLLM-data/fairness/stereotype_recognition.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: stereotype_agreement
    data_path: /path/to/TrustLLM-data/fairness/stereotype_agreement.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: stereotype_query
    data_path: /path/to/TrustLLM-data/fairness/stereotype_query_test.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: disparagement
    data_path: /path/to/TrustLLM-data/fairness/disparagement.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: preference
    data_path: /path/to/TrustLLM-data/fairness/preference.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

emotions: [anger, neutral]
intensities: [1.0]

output_dir: results/memory_experiments
batch_size: 4

sanity_check: false

generation_config:
  temperature: 0.0
  max_new_tokens: 128
  do_sample: false

loading_config:
  model_path: /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct
  gpu_memory_utilization: 0.90
  tensor_parallel_size: 1
  max_model_len: 8192
  enforce_eager: true
  trust_remote_code: true
  dtype: float16
  seed: 42
  disable_custom_all_reduce: false
  additional_vllm_kwargs: {}


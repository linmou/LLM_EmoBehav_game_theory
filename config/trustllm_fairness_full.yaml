# Full TrustLLM Fairness run (stereotype_recognition, stereotype_agreement,
# stereotype_query, disparagement, preference)
# Edit the data_path values to point to your local TrustLLM fairness JSON files.
# Typical filenames (from TrustLLM docs):
#   stereotype_recognition.json
#   stereotype_agreement.json
#   stereotype_query_test.json
#   disparagement.json
#   preference.json

models:
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-0.5B-Instruct
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-1.5B-Instruct
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen2.5-3B-Instruct
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen3-0.6B
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen3-1.7B
  # - /data/home/jjl7137/huggingface_models/Qwen/Qwen3-4B
  - "meta-llama/Llama-3.2-1B-Instruct"
  - "meta-llama/Llama-3.2-3B-Instruct"
  # - "HuggingFaceTB/SmolLM3-3B"
  # - "HuggingFaceTB/SmolLM2-1.7B-Instruct"
  # - "HuggingFaceTB/SmolLM2-360M-Instruct"
  # - "HuggingFaceTB/SmolLM2-135M-Instruct"
  # - "facebook/MobileLLM-R1-950M"
  # - "facebook/MobileLLM-R1-360M"
  # - "facebook/MobileLLM-R1-140M"
  - "microsoft/Phi-3.5-mini-instruct"
  - "microsoft/Phi-4-mini-instruct"
  - "google/gemma-3-1b-it"
  - "google/gemma-3-270m-it"


benchmarks:
  - name: trustllm_fairness
    task_type: stereotype_recognition
    data_path: /data/home/jjl7137/TrustLLM/data/TrustLLM/dataset/fairness/stereotype_recognition.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: stereotype_agreement
    data_path: /data/home/jjl7137/TrustLLM/data/TrustLLM/dataset/fairness/stereotype_agreement.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: stereotype_query
    data_path: /data/home/jjl7137/TrustLLM/data/TrustLLM/dataset/fairness/stereotype_query_test.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: disparagement
    data_path: /data/home/jjl7137/TrustLLM/data/TrustLLM/dataset/fairness/disparagement.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

  - name: trustllm_fairness
    task_type: preference
    data_path: /data/home/jjl7137/TrustLLM/data/TrustLLM/dataset/fairness/preference.json
    enable_auto_truncation: false
    truncation_strategy: right
    preserve_ratio: 0.8
    llm_eval_config:
      model: gpt-4o-mini
      temperature: 0.0

emotions: ["anger", "happiness", "sadness", "fear", "disgust", "surprise"]
intensities: [1.5]

output_dir: results/TrustLLM_fairness
batch_size: 500

repeat_runs: 3
repeat_seed_base: 123

sanity_check: false

generation_config:
  temperature: 0.0
  max_new_tokens: 1000
  do_sample: false

loading_config:
  gpu_memory_utilization: 0.90
  enforce_eager: true
  trust_remote_code: true
  dtype: bfloat16
  seed: 42
  disable_custom_all_reduce: false
  additional_vllm_kwargs: {}

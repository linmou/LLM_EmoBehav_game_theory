{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#project-documentation","title":"Project Documentation","text":"<p>This directory contains documentation for the different modules within the LLM_EmoBehav_game_theory project.</p>"},{"location":"#modules","title":"Modules","text":"<ul> <li>Scenario Creation:<ul> <li>LangGraph Implementation: Details on the graph-based process for generating game theory scenarios.</li> </ul> </li> <li> <p>Games:</p> <ul> <li>See the <code>docs/games/</code> directory for specific game configurations and details.</li> </ul> </li> <li> <p>Representation Reading (RepE): </p> <ul> <li>Extracting Emotion Activation Directions</li> </ul> </li> <li> <p>Emotion Analysis:</p> <ul> <li>Emotion Analysis - Documentation for emotion analysis</li> </ul> </li> <li> <p>Model Layer Detector:</p> <ul> <li>Model Layer Detector - Documentation for model layer detector</li> </ul> </li> <li> <p>Prompt Format:</p> <ul> <li>Prompt Format - Documentation for prompt format</li> </ul> </li> <li> <p>Prompt Wrapper:</p> <ul> <li>Prompt Wrapper - Documentation for prompt wrapper</li> </ul> </li> <li> <p>Experiment Series:</p> <ul> <li>Experiment Series - Documentation for experiment series</li> </ul> </li> <li> <p>vLLM Integration:</p> <ul> <li>vLLM Compatibility - Documentation for vLLM compatibility with representation engineering</li> <li>vLLM Hook Implementation - Explains the <code>RepControlVLLMHook</code> for representation control using vLLM hooks.</li> </ul> </li> <li> <p>... (Add links to other documentation as needed)</p> </li> </ul>"},{"location":"documentation_guide/","title":"Project Documentation (<code>docs</code>)","text":"<p>This directory contains the source Markdown files for the project documentation. The documentation is built using MkDocs with the Material for MkDocs theme.</p>"},{"location":"documentation_guide/#building-the-documentation-locally","title":"Building the Documentation Locally","text":"<p>To build and serve the documentation locally for development and preview:</p> <ol> <li> <p>Ensure MkDocs is installed:     If you haven't already, install MkDocs and the Material theme (preferably in your project's Python virtual environment):     <pre><code>pip install mkdocs mkdocs-material\n</code></pre>     (Remember to activate your conda environment first if you're using one, e.g., <code>conda activate llm</code>)</p> </li> <li> <p>Navigate to the project root:     Open your terminal in the root directory of this project (where <code>mkdocs.yml</code> is located).</p> </li> <li> <p>Serve the documentation:     Run the following command:     <pre><code>mkdocs serve\n</code></pre>     This will start a local development server. You can view the documentation by opening your web browser to the address shown in the output (usually <code>http://127.0.0.1:8000</code>). The site will automatically rebuild and reload when you save changes to the documentation files or <code>mkdocs.yml</code>.</p> </li> <li> <p>Stop the local server:     Press <code>Ctrl+C</code> in the terminal where <code>mkdocs serve</code> is running.</p> </li> </ol>"},{"location":"documentation_guide/#building-static-html-files","title":"Building Static HTML Files","text":"<p>To generate the static HTML files (e.g., for deployment to a web server or GitHub Pages):</p> <ol> <li>Navigate to the project root.</li> <li>Run the build command:     <pre><code>mkdocs build\n</code></pre>     This will create a <code>site</code> directory in your project root containing the complete static documentation website. You can then deploy the contents of this <code>site</code> directory.</li> </ol>"},{"location":"documentation_guide/#editing-content","title":"Editing Content","text":"<ul> <li>Source Files: All documentation content is in Markdown files (<code>.md</code>) within this <code>docs</code> directory and its subdirectories (like <code>docs/reference</code>).</li> <li>Navigation: The site navigation is defined in the <code>nav</code> section of the <code>mkdocs.yml</code> file in the project root.</li> <li>Configuration: Site appearance, plugins, and other settings are configured in <code>mkdocs.yml</code>.</li> </ul>"},{"location":"documentation_guide/#adding-new-pages","title":"Adding New Pages","text":"<ol> <li>Create a new Markdown file (e.g., <code>docs/reference/new_topic.md</code>).</li> <li>Add your content to the new file.</li> <li>Update the <code>nav</code> section in <code>mkdocs.yml</code> to include a link to your new page.</li> </ol>"},{"location":"documentation_guide/#committing-documentation-changes","title":"Committing Documentation Changes","text":"<p>Remember to commit changes to: -   The Markdown files in the <code>docs</code> directory. -   The <code>mkdocs.yml</code> configuration file if you change navigation or site settings. -   Any new assets (like images) added to the <code>docs</code> directory.</p> <p>Do NOT commit the <code>site</code> directory generated by <code>mkdocs build</code> unless you have a specific reason for doing so (e.g., deploying via GitHub Pages from the <code>gh-pages</code> branch or a <code>docs</code> folder on <code>main</code>, depending on your setup). </p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/","title":"LangGraph Scenario Creation","text":"<p>This module handles the creation of game theory scenarios using LangGraph, a library for building stateful, multi-step AI applications with LLMs.</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#overview","title":"Overview","text":"<p>The scenario creation process uses a sequential workflow to generate and refine game theory scenarios:</p> <ol> <li>Propose Scenario: Generate an initial scenario draft for the specified game</li> <li>Verify Narrative: Check if the scenario narrative is realistic and coherent</li> <li>Verify Preference Order: Ensure the game mechanics are correctly implemented</li> <li>Verify Pay Off: Validate that the outcomes described are plausible </li> <li>Aggregate Verification: Synchronize the verification results</li> <li>Decision Point: Continue refining or finalize the scenario</li> </ol>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#implementation-details","title":"Implementation Details","text":"<p>The graph was originally designed with parallel verification steps, but due to LangGraph concurrency limitations where multiple nodes can't update the same state keys simultaneously, we've adopted a sequential approach instead.</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#key-components","title":"Key Components","text":"<ul> <li>StateGraph: Manages the state transitions between different stages of scenario creation</li> <li>State Definition: <code>ScenarioCreationState</code> holds input requirements, working data, and output</li> <li>Node Functions: Each function processes the state and produces new values</li> <li>Edge Logic: Conditional transitions based on verification results</li> </ul>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#usage","title":"Usage","text":"<pre><code>from data_creation.scenario_creation import create_scenario, a_create_scenario\nfrom data_creation.scenario_creation.langgraph_creation import build_scenario_creation_graph\n\n# Synchronous approach (for simple use cases)\nscenario = create_scenario(\n    game_name=\"Prisoners_Dilemma\",\n    participants=[\"Alice\", \"Bob\"],\n    participant_jobs=[\"lawyer\", \"lawyer\"]\n)\n\n# Asynchronous approach (recommended for web applications)\nasync def create_scenario_async():\n    graph = build_scenario_creation_graph()\n\n    # Configure with recursion limit to avoid errors in complex scenarios\n    config = {\n        \"configurable\": {\"thread_id\": \"unique_id\"},\n        \"recursion_limit\": 50  # Important to prevent recursion limit errors\n    }\n\n    scenario = await a_create_scenario(\n        graph=graph,\n        game_name=\"Prisoners_Dilemma\", \n        participants=[\"Alice\", \"Bob\"],\n        participant_jobs=[\"lawyer\", \"lawyer\"],\n        auto_save_path=\"./scenarios\",  # Optional path to save generated scenarios\n        config=config  # Pass the config with recursion_limit\n    )\n    return scenario\n</code></pre>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#recursion-limit-errors","title":"Recursion Limit Errors","text":"<p>If you encounter this error:  <pre><code>Error invoking graph: Recursion limit of 25 reached without hitting a stop condition\n</code></pre></p> <p>Make sure to: 1. Pass a <code>config</code> parameter to <code>a_create_scenario</code> with a higher <code>recursion_limit</code> (e.g., 50) 2. Ensure the <code>finalize_scenario</code> function properly sets the <code>final_scenario</code> even when verification hasn't fully converged</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#concurrency-errors","title":"Concurrency Errors","text":"<p>If you encounter the error: <code>Can receive only one value per step. Use an Annotated key to handle multiple values</code>, make sure you're using the sequential graph structure that avoids parallel updates to the same state keys.</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#api-gateway-issues","title":"API Gateway Issues","text":"<p>For handling API gateway issues (like 502 Bad Gateway), consider implementing retry mechanisms and adjusting the frequency of API calls to stay within rate limits.</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#dependencies","title":"Dependencies","text":"<ul> <li>langgraph</li> <li>langchain</li> <li>openai</li> </ul>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#scenario-creation-graph","title":"Scenario Creation Graph","text":"<p>This module uses LangGraph to create game theory scenarios with parallel verification steps.</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#architecture","title":"Architecture","text":"<p>The scenario creation process follows these main steps:</p> <ol> <li>propose_scenario: Creates an initial scenario draft based on game requirements</li> <li>verification (parallel steps):</li> <li>verify_narrative: Checks the narrative quality and coherence</li> <li>verify_preference_order: Validates game-theoretic mechanics</li> <li>verify_pay_off: Ensures payoff plausibility</li> <li>aggregate_verification: Combines results from parallel verification steps</li> <li>conditional branching:</li> <li>If all verifications passed OR max iterations reached: finalize_scenario</li> <li>Otherwise: Loop back to propose_scenario for refinement</li> </ol>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#parallel-processing","title":"Parallel Processing","text":"<p>The verification steps run in parallel, which offers several advantages: - Faster execution as all verifications happen simultaneously - Independent validation of different aspects of the scenario - Comprehensive feedback collected in a single iteration</p>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#implementation-details_1","title":"Implementation Details","text":"<ul> <li>Uses LangGraph's fan-out/fan-in pattern for parallel execution</li> <li>State reducers (specifically <code>operator.add</code>) combine feedback from parallel nodes</li> <li>Node functions only return the specific fields they modify, not the entire state</li> <li>The <code>aggregate_verification</code> node consolidates verification results</li> </ul>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#state-management","title":"State Management","text":"<p>The <code>ScenarioCreationState</code> class includes reducers for feedback lists to properly handle updates from parallel nodes. Instead of accumulating feedback across iterations using <code>operator.add</code>, we now use a custom <code>replace_reducer</code> to ensure only the latest feedback from the verification steps is kept in the state:</p> <pre><code># Custom reducer function\ndef replace_reducer(existing_value, new_value):\n    return new_value\n\nclass ScenarioCreationState(TypedDict):\n    # ...\n    narrative_feedback: Annotated[List[str], replace_reducer]\n    preference_feedback: Annotated[List[str], replace_reducer]\n    payoff_feedback: Annotated[List[str], replace_reducer]\n    # ...\n</code></pre>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#handling-concurrency-issues","title":"Handling Concurrency Issues","text":"<p>To avoid the error: <code>Can receive only one value per step. Use an Annotated key to handle multiple values</code>, we:</p> <ol> <li>Modified node functions to return only the specific fields they update</li> <li>Used reducers (like the <code>replace_reducer</code> shown above) for any fields that might be updated in parallel</li> <li>Created a dedicated <code>all_converged</code> field to track overall convergence</li> </ol>"},{"location":"code_readme/data_creation/scenario_creation/langgraph_creation/#troubleshooting_1","title":"Troubleshooting","text":"<p>If you encounter concurrency errors, ensure: - Node functions only return fields they need to modify - Any fields that might be updated in parallel use reducers - The <code>recursion_limit</code> is set to a reasonable value in the configuration</p>"},{"location":"code_readme/neuro_manipulation/","title":"Neuro-Manipulation Toolkit","text":"<p>This toolkit provides functionalities for exploring and manipulating the internal representations of language models, particularly focusing on emotions. It allows users to:</p> <ol> <li>Extract Emotion Representations: Identify and extract \"steering vectors\" that represent specific emotions (e.g., anger, joy) within the model\\'s hidden states.</li> <li>Run Controlled Experiments: Conduct experiments by injecting these emotion steering vectors into a model during inference to observe their impact on behavior, such as decision-making in game scenarios.</li> </ol>"},{"location":"code_readme/neuro_manipulation/#core-components-and-workflow","title":"Core Components and Workflow","text":"<p>The toolkit revolves around a few key components and processes:</p>"},{"location":"code_readme/neuro_manipulation/#1-extracting-emotion-activation-directions-steering-vectors","title":"1. Extracting Emotion Activation Directions (Steering Vectors)","text":"<p>This process uses the <code>RepReadingPipeline</code> and the <code>all_emotion_rep_reader</code> utility function to discover directions in a model\\'s activation space that correspond to specific emotions.</p> <p>Conceptual Steps:</p> <ol> <li> <p>Data Preparation:</p> <ul> <li>Organize text data into a dictionary where keys are emotion labels (e.g., \\'anger\\', \\'joy\\').</li> <li>Each emotion maps to \\'train\\' and \\'test\\' lists of text examples.</li> <li>For directional methods like \\'pca\\' or \\'rotation\\', provide contrastive pairs (e.g., [negative_example, positive_example,...]).</li> </ul> </li> <li> <p>Pipeline Initialization:</p> <ul> <li>Set up a <code>RepReadingPipeline</code> with a transformer model and tokenizer. <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n# Assuming RepReadingPipeline is correctly importable\nfrom neuro_manipulation.repe import RepReadingPipeline\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.1\" # Example\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\nrep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer, pipeline_class=RepReadingPipeline)\n</code></pre></li> </ul> </li> <li> <p>Parameter Definition:</p> <ul> <li><code>emotions</code>: List of target emotions.</li> <li><code>hidden_layers</code>: Model layers to extract hidden states from.</li> <li><code>rep_token</code>: Token index for representation analysis (e.g., -1 for the last token).</li> <li><code>n_difference</code>: Number of differences between input pairs (for methods like \\'pca\\').</li> <li><code>direction_method</code>: Strategy like \\'pca\\', \\'rotation\\', or \\'clustermean\\'.</li> <li><code>save_path</code>: Optional path to save the <code>RepReader</code> objects.</li> </ul> </li> <li> <p>Execution:</p> <ul> <li>Call <code>all_emotion_rep_reader</code> with the data, pipeline, and parameters. <pre><code># Assuming all_emotion_rep_reader is correctly importable\nfrom neuro_manipulation.utils import all_emotion_rep_reader\n\n# emotions, hidden_layers, data, etc. are defined\nemotion_rep_readers = all_emotion_rep_reader(\n    data=data,\n    emotions=emotions,\n    rep_reading_pipeline=rep_reading_pipeline,\n    # ... other parameters\n)\n</code></pre></li> </ul> </li> <li> <p>Results:</p> <ul> <li>The function returns a dictionary containing trained <code>RepReader</code> objects for each emotion.</li> <li>Each <code>RepReader</code> stores the <code>directions</code> (layer-wise emotion vectors) and <code>direction_signs</code>.</li> <li>It also includes layer-wise accuracy and the arguments used.</li> </ul> </li> </ol> <p>Internal Mechanics:</p> <ul> <li>The <code>RepReadingPipeline</code> extracts hidden states for specified tokens and layers.</li> <li>It then uses a <code>DIRECTION_FINDER</code> (e.g., PCA) on these hidden states (or their differences) to compute the direction vectors.</li> <li>The <code>all_emotion_rep_reader</code> function orchestrates this for multiple emotions, including a validation step to assess the quality of the learned directions using test data.</li> </ul> <p>The output is a set of vectors (one per layer per emotion) representing the identified emotional directions in the model\\'s activation space.</p> <p>(For more details, refer to <code>docs/code_readme/neuro_manipulation/repe/README_extract_emotion_repe.md</code>)</p>"},{"location":"code_readme/neuro_manipulation/#2-emotion-game-experiment-logic-emotion_game_experimentpy","title":"2. Emotion Game Experiment Logic (<code>emotion_game_experiment.py</code>)","text":"<p>The <code>EmotionGameExperiment</code> class is designed to investigate how injecting these learned emotion steering vectors affects a language model\\'s behavior in game-like scenarios that require decision-making.</p> <p>Experiment Workflow:</p> <ol> <li> <p>Initialization (<code>__init__</code>):</p> <ul> <li>Sets up logging.</li> <li>Loads configurations for the RepE engine, the experiment itself, and the game.</li> <li>Initializes the model and tokenizer (supports both Hugging Face Transformers and vLLM).<ul> <li>Crucially, it loads the pre-computed <code>emotion_rep_readers</code> (steering vectors) using <code>load_emotion_readers</code>.</li> </ul> </li> <li>Determines the hidden layers to be targeted for manipulation.</li> <li>Initializes a <code>rep_control_pipeline</code> (either <code>rep-control</code> for standard Transformers or <code>rep-control-vllm</code> for vLLM) which will be responsible for applying the steering vectors during inference. This pipeline is configured with the control layers, block name (e.g., \\'decoder_block\\'), and control method.</li> <li>Sets up a <code>GameReactPromptWrapper</code> to format prompts for the game scenarios and parse model responses.</li> <li>Prepares an output directory for saving results and configurations.</li> </ul> </li> <li> <p>Data Loading (<code>build_dataloader</code>):</p> <ul> <li>Creates a <code>GameScenarioDataset</code> which provides game scenarios, descriptions, and options.</li> <li>The dataset uses the <code>GameReactPromptWrapper</code> to format the input prompts for the LLM.</li> <li>A PyTorch <code>DataLoader</code> is used to batch these scenarios.</li> </ul> </li> <li> <p>Running the Experiment (<code>run_experiment</code>):</p> <ul> <li>Iterates through each specified <code>emotion</code> and each <code>intensity</code> (coefficient) for applying the emotion.</li> <li>For each emotion, retrieves the corresponding <code>RepReader</code> (containing the steering vectors).</li> <li>For each intensity, calls <code>_infer_with_activation</code>.</li> <li>Also runs a \"Neutral\" condition (zero intensity) as a baseline.</li> <li>Saves all results.</li> </ul> </li> <li> <p>Inference with Activation Control (<code>_infer_with_activation</code>):</p> <ul> <li>Constructs the <code>activations</code> dictionary. This maps each target layer index to a tensor representing <code>coefficient * direction_vector * direction_sign</code>. This is the actual \"steering\" signal.</li> <li>Calls <code>_forward_dataloader</code> to process the game scenarios with these activations.</li> </ul> </li> <li> <p>Forwarding Data through Model (<code>_forward_dataloader</code>):</p> <ul> <li>This method processes batches of game scenarios.</li> <li>It uses a worker thread (<code>pipeline_worker</code>) and a <code>Queue</code> to manage the flow of data and results, allowing for asynchronous generation and post-processing.</li> <li>For each batch:<ul> <li>It repeats samples within the batch if <code>self.repeat &gt; 1</code>.</li> <li>It calls the <code>self.rep_control_pipeline</code> with the prompts and the prepared <code>activations</code>. This is where the model generates responses while under the influence of the injected emotion.</li> <li>The generation parameters (temperature, max tokens, etc.) are taken from the experiment configuration.</li> </ul> </li> <li>A <code>ThreadPoolExecutor</code> is used to parallelize the post-processing of the generated outputs.</li> </ul> </li> <li> <p>Post-Processing Batch Results (<code>_post_process_batch</code>):</p> <ul> <li>For each generated output in a batch:<ul> <li>Extracts the raw generated text.</li> <li>Calls <code>_post_process_single_output</code> to parse the rationale and decision from the text.</li> <li>Formats and collects the results, including emotion, intensity, scenario details, input prompt, raw output, parsed rationale, decision, chosen option category, and repeat number.</li> </ul> </li> </ul> </li> <li> <p>Post-Processing Single Output (<code>_post_process_single_output</code>):</p> <ul> <li>Attempts to extract the \"rationale\" and \"decision\" from the model\\'s generated text using regex patterns.</li> <li>If regex fails, it falls back to using an LLM (e.g., GPT-4o-mini via <code>_get_option_id_from_llm</code>) to interpret the output and identify the chosen option.</li> <li>Determines the <code>option_id</code> corresponding to the extracted decision.</li> </ul> </li> <li> <p>Saving Results (<code>_save_results</code>):</p> <ul> <li>Saves the collected experimental data to JSON and CSV files.</li> <li>Calls <code>_run_statistical_analysis</code> to perform statistical tests on the results.</li> </ul> </li> <li> <p>Statistical Analysis (<code>_run_statistical_analysis</code>):</p> <ul> <li>Uses an external <code>analyze_emotion_and_intensity_effects</code> function (from <code>statistical_engine</code>) to analyze the impact of different emotions and intensities on the model\\'s decisions.</li> <li>Saves these statistical results.</li> </ul> </li> <li> <p>Sanity Check (<code>run_sanity_check</code>):</p> <ul> <li>Provides a way to run a small version of the experiment (e.g., 10 samples, one emotion, one intensity) to quickly validate the setup.</li> </ul> </li> </ol> <p>This experiment systematically tests how nudging the model\\'s internal state with emotion-specific vectors influences its choices in defined scenarios.</p>"},{"location":"code_readme/neuro_manipulation/#3-inference-with-vllm-hooks-repcontrolvllmhook","title":"3. Inference with vLLM Hooks (<code>RepControlVLLMHook</code>)","text":"<p>When using vLLM for faster inference, the <code>RepControlVLLMHook</code> class (detailed in <code>docs/reference/vllm_hook_implementation.md</code>) enables applying representation control.</p> <p>Mechanism:</p> <ol> <li> <p>Initialization:</p> <ul> <li>A <code>RepControlVLLMHook</code> instance is created with the vLLM <code>LLM</code> object, tokenizer, target layer indices, the module name within the layer to hook (e.g., <code>\"decoder_block\"</code>), and the control method.</li> <li>It uses vLLM\\'s <code>collective_rpc</code> (Remote Procedure Call) to register a forward hook (<code>hook_fn_rep_control</code>) on the specified module of the model on each vLLM worker process.</li> <li>Initially, the hook is dormant as no control state is set.</li> </ul> </li> <li> <p>Controlled Generation (<code>__call__</code> method of the hook, or via <code>rep-control-vllm</code> pipeline):</p> <ul> <li>Set State: Before running inference, if <code>activations</code> (the steering vectors scaled by intensity) are provided, an RPC call (<code>_set_controller_state_on_worker_rpc</code>) is made to each worker. This attaches the control parameters (steering vector for that layer, mask, operator, etc.) as a <code>_rep_control_state</code> attribute to the hooked module on that worker.</li> <li>Run Inference: Standard <code>model.generate()</code> is called (vLLM handles the distributed inference).<ul> <li>When the forward pass on a worker reaches a hooked module, <code>hook_fn_rep_control</code> executes.</li> <li>The hook checks for the <code>_rep_control_state</code>.</li> <li>If present, it retrieves the control tensor and other parameters and modifies the module\\'s output (e.g., by adding the steering vector).</li> <li>If no state is present, it passes the original output through.</li> </ul> </li> <li>Reset State: After generation, another RPC call (<code>_reset_controller_state_on_worker_rpc</code>) removes the <code>_rep_control_state</code> from the modules on all workers. This ensures subsequent inference calls are not affected.</li> </ul> </li> <li> <p>Hook Function (<code>hook_fn_rep_control</code>):</p> <ul> <li>This is the core logic that applies the representation modification (e.g., adding the control vector to the module\\'s output), similar to how <code>WrappedBlock.forward</code> would work in non-vLLM setups. It handles tensor manipulations, masking, and applying the operator.</li> </ul> </li> </ol> <p>Advantages:</p> <ul> <li>Integrates with vLLM without modifying its core model structure.</li> <li>Uses vLLM\\'s RPC for managing distributed state (the control vectors).</li> </ul> <p>Considerations:</p> <ul> <li>RPC calls introduce some overhead.</li> <li>State management complexity relies on the RPC mechanism.</li> <li>Hooks might interact with vLLM\\'s internal optimizations; <code>enforce_eager=True</code> might be needed for the vLLM <code>LLM</code> object.</li> </ul> <p>(For more details, see <code>docs/reference/vllm_hook_implementation.md</code>)</p>"},{"location":"code_readme/neuro_manipulation/#how-to-use","title":"How to Use","text":"<ol> <li>Environment Setup: Ensure all dependencies, including <code>transformers</code>, <code>torch</code>, <code>vllm</code> (if used), and other packages listed in <code>emotion_game_experiment.py</code> are installed.</li> <li>Configuration:<ul> <li>Prepare configuration files (YAML) for:<ul> <li>RepE Engine (<code>repe_eng_config</code>): Specifies model details, layers for control, block names, control method, paths to emotion datasets for <code>RepReader</code> training, etc.</li> <li>Experiment (<code>exp_config</code>): Defines emotions to test, intensity coefficients, LLM generation parameters, output directories, system messages for prompts.</li> <li>Game (<code>game_config</code>): Specifies the game data path, decision class structure for parsing outputs.</li> </ul> </li> </ul> </li> <li>Prepare Emotion Representations(Optional):<ul> <li>If not already done, run the process described in \"Extracting Emotion Activation Directions\" to generate and save <code>RepReader</code> objects for your target emotions and model. Ensure the <code>load_emotion_readers</code> function in <code>EmotionGameExperiment</code> can access these.</li> <li>The <code>EmotionGameExperiment</code> includes the logic that generates and saves <code>RepReader</code> objects if not exists. </li> </ul> </li> <li>Run an Experiment:<ul> <li>Instantiate <code>EmotionGameExperiment</code> with the loaded configurations.</li> <li>Call the <code>run_experiment()</code> method to execute the full experiment.</li> <li>Alternatively, call <code>run_sanity_check()</code> for a quick test.</li> </ul> </li> </ol>"},{"location":"code_readme/neuro_manipulation/#directory-structure-key-files","title":"Directory Structure (Key Files)","text":"<ul> <li><code>neuro_manipulation/</code><ul> <li><code>experiments/</code><ul> <li><code>emotion_game_experiment.py</code>: Main script for running emotion manipulation experiments.</li> </ul> </li> <li><code>repe/</code><ul> <li><code>README_extract_emotion_repe.md</code>: (Reference) Detailed guide on extracting emotion vectors.</li> <li><code>pipelines.py</code>: Contains <code>RepReadingPipeline</code> and <code>RepControlPipeline</code> (and their vLLM variants).</li> <li><code>rep_control_vllm_hook.py</code>: (Reference) Implements the vLLM hook mechanism.</li> </ul> </li> <li><code>datasets/</code><ul> <li><code>game_scenario_dataset.py</code>: Defines the dataset for game scenarios.</li> </ul> </li> <li><code>utils/</code><ul> <li><code>all_emotion_rep_reader</code> (likely here or in a similar utility script): Function to train all emotion readers.</li> <li>Other helper functions.</li> </ul> </li> <li><code>model_utils.py</code>: Utilities for model and tokenizer setup, loading emotion readers.</li> <li><code>prompt_wrapper.py</code>: For formatting prompts and structuring responses.</li> <li><code>README.md</code>: (This file) Overview of the toolkit.</li> </ul> </li> <li><code>docs/</code><ul> <li><code>code_readme/neuro_manipulation/repe/README.md</code>: (Linked from <code>current_file</code>) Likely a duplicate or older version of <code>README_extract_emotion_repe.md</code>.</li> <li><code>reference/vllm_hook_implementation.md</code>: (Linked from <code>current_file</code>) Detailed explanation of the vLLM hook.</li> </ul> </li> </ul> <p>This toolkit provides a comprehensive framework for investigating and influencing LLM behavior through targeted manipulations of their internal emotional representations. </p>"},{"location":"code_readme/neuro_manipulation/repe/README_extract_emotion_repe/","title":"Extracting Emotion Activation Directions using RepReadingPipeline","text":"<p>This document explains how to use the <code>RepReadingPipeline</code> and the utility function <code>all_emotion_rep_reader</code> to identify the activation directions associated with different emotions within the hidden states of a language model.</p>"},{"location":"code_readme/neuro_manipulation/repe/README_extract_emotion_repe/#overview","title":"Overview","text":"<p>The core idea is to train a \"representation reader\" (<code>RepReader</code>) for each emotion. This reader learns a direction in the model's activation space (specifically, within the hidden states of specified layers) that corresponds to the presence or intensity of that emotion.</p> <p>The <code>RepReadingPipeline</code> provides the mechanism to access the model's hidden states for given inputs. The <code>all_emotion_rep_reader</code> function orchestrates this process across multiple emotions, handling data preparation, training the <code>RepReader</code> for each emotion, and saving the results.</p>"},{"location":"code_readme/neuro_manipulation/repe/README_extract_emotion_repe/#steps","title":"Steps","text":"<ol> <li> <p>Prepare Data:</p> <ul> <li>Organize your data into a dictionary structure where keys are emotion labels (e.g., 'anger', 'joy').</li> <li>Each emotion key should map to another dictionary containing 'train' and 'test' keys.</li> <li>The 'train' and 'test' values should be lists of text inputs representing examples of that emotion. For directional methods like 'pca' or 'rotation', these lists should contain pairs of texts (e.g., [negative_example, positive_example, negative_example, positive_example,...]). For 'clustermean', single examples are sufficient.</li> </ul> </li> <li> <p>Initialize <code>RepReadingPipeline</code>:</p> <ul> <li>Instantiate the <code>RepReadingPipeline</code> with the desired transformer model and tokenizer. <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom neuro_manipulation.repe import RepReadingPipeline # Assuming RepReadingPipeline is in this path\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.1\" # Example model\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id # Or another appropriate pad token ID\n\nrep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer, pipeline_class=RepReadingPipeline)\n</code></pre></li> </ul> </li> <li> <p>Define Parameters:</p> <ul> <li><code>emotions</code>: A list of emotion strings you want to find directions for.</li> <li><code>hidden_layers</code>: A list of layer indices (e.g., <code>[-1]</code>, <code>[0, 6, 12]</code>) from which to extract hidden states.</li> <li><code>rep_token</code>: The index of the token whose representation you want to analyze (e.g., -1 for the last token).</li> <li><code>n_difference</code>: The number of times to take differences between consecutive pairs in the input. Typically 1 for methods like 'pca'.</li> <li><code>direction_method</code>: The strategy for finding directions ('pca', 'rotation', 'clustermean').</li> <li><code>save_path</code>: Optional path to save the resulting <code>RepReader</code> objects.</li> </ul> </li> <li> <p>Call <code>all_emotion_rep_reader</code>:</p> <ul> <li>Pass the prepared data, initialized pipeline, and parameters to the function. <pre><code>from neuro_manipulation.utils import all_emotion_rep_reader # Assuming the function is here\n\n# Example parameters\nemotions = ['anger', 'joy', 'sadness']\nhidden_layers = [-1] # Last layer\nrep_token = -1\nn_difference = 1\ndirection_method = 'pca'\nsave_path = 'exp_records/emotion_rep_readers.pkl'\nread_args = { # Store parameters used\n    'rep_token': rep_token,\n    'hidden_layers': hidden_layers,\n    'n_difference': n_difference,\n    'direction_method': direction_method,\n}\n\n\n# Assuming 'data' is the prepared data dictionary from step 1\nemotion_rep_readers = all_emotion_rep_reader(\n    data=data,\n    emotions=emotions,\n    rep_reading_pipeline=rep_reading_pipeline,\n    hidden_layers=hidden_layers,\n    rep_token=rep_token,\n    n_difference=n_difference,\n    direction_method=direction_method,\n    save_path=save_path,\n    read_args=read_args\n)\n</code></pre></li> </ul> </li> <li> <p>Access Results:</p> <ul> <li>The <code>all_emotion_rep_reader</code> function returns a dictionary (<code>emotion_rep_readers</code>).</li> <li>This dictionary contains the trained <code>RepReader</code> object for each emotion under its respective key (e.g., <code>emotion_rep_readers['anger']</code>).</li> <li>Each <code>RepReader</code> object holds the calculated <code>directions</code> (a dictionary mapping layer index to the direction vector) and potentially <code>direction_signs</code>.</li> <li>The dictionary also stores the accuracy per layer for each emotion under <code>emotion_rep_readers['layer_acc']</code> and the parameters used under <code>emotion_rep_readers['args']</code>.</li> </ul> </li> </ol>"},{"location":"code_readme/neuro_manipulation/repe/README_extract_emotion_repe/#how-it-works-internally","title":"How it Works Internally","text":"<ul> <li><code>RepReadingPipeline._forward</code>: Extracts hidden states from the specified <code>hidden_layers</code> for the <code>rep_token</code> of the input sequences.</li> <li><code>RepReadingPipeline._get_hidden_states</code>: Processes the model outputs to isolate the desired hidden states.</li> <li><code>RepReadingPipeline.get_directions</code>:<ul> <li>Uses <code>_batched_string_to_hiddens</code> to get hidden states for all training inputs.</li> <li>Calculates differences between pairs of hidden states if <code>n_difference &gt; 0</code>.</li> <li>Initializes a <code>DIRECTION_FINDER</code> based on <code>direction_method</code>.</li> <li>Calls the finder's <code>get_rep_directions</code> method, passing the (potentially differenced) hidden states to compute the direction vectors for each layer.</li> <li>Optionally computes <code>direction_signs</code> to orient the directions consistently.</li> </ul> </li> <li><code>all_emotion_rep_reader</code>:<ul> <li>Iterates through each specified <code>emotion</code>.</li> <li>Calls <code>get_rep_reader</code> (which likely wraps <code>RepReadingPipeline.get_directions</code> and evaluates accuracy) for each emotion's train/test data.<ul> <li>Validation Step (within <code>get_rep_reader</code>/<code>test_direction</code>):<ul> <li>Assumes the <code>test_data</code> follows the same structure as <code>train_data</code> (e.g., contrastive pairs if used for training).</li> <li>Uses the trained <code>rep_reader</code> (containing directions and signs) to transform the hidden states of the <code>test_data</code> via <code>RepReadingPipeline</code>. This projects the test hidden states onto the learned direction.</li> <li>Compares the projection scores of adjacent examples (the contrastive pairs) in the test set.</li> <li>Checks if the example with the higher/lower score within the pair matches the expected sign (<code>rep_reader.direction_signs</code>) determined during training. For instance, if the sign is +1, it checks if the second element of the pair (presumed positive) has a higher projection score.</li> <li>Calculates the accuracy based on how often this expected relationship holds true across all test pairs. This accuracy is stored in <code>emotion_rep_readers['layer_acc']</code>.</li> </ul> </li> </ul> </li> <li>Stores the resulting <code>RepReader</code> and accuracy.</li> <li>Saves the collected readers and metadata to a file if <code>save_path</code> is provided.</li> </ul> </li> </ul> <p>This process yields a set of vectors, one per layer per emotion, representing the direction in activation space associated with that emotion. These directions can then be used for analysis or manipulation of model behavior. </p>"},{"location":"code_readme/neuro_manipulation/tests/","title":"Neuro-Manipulation Tests","text":"<p>This directory contains tests for the utilities within the <code>neuro_manipulation</code> package.</p>"},{"location":"code_readme/neuro_manipulation/tests/#tests","title":"Tests","text":""},{"location":"code_readme/neuro_manipulation/tests/#test_model_layer_detectorpy","title":"<code>test_model_layer_detector.py</code>","text":"<p>Contains unit tests for the <code>ModelLayerDetector</code> class. These tests verify its ability to correctly identify transformer layers across various model architectures, including:</p> <ul> <li>Standard HuggingFace models (GPT-2, OPT)</li> <li>Models with different layer naming conventions (ChatGLM)</li> <li>Non-standard architectures (RWKV - requires <code>trust_remote_code=True</code>)</li> <li>Custom-built simple transformer models</li> <li>Models loaded via vLLM</li> </ul>"},{"location":"code_readme/neuro_manipulation/tests/#test_vllm_hook_registrationpy","title":"<code>test_vllm_hook_registration.py</code>","text":"<p>Tests the ability to register PyTorch forward hooks on transformer layers within a model served by vLLM.</p> <ul> <li>Uses <code>ModelLayerDetector</code> to find the target layers dynamically.</li> <li>Initializes a vLLM <code>LLM</code> instance with standard models (e.g., GPT-2, OPT-125m, Llama-2-7b).</li> <li>Accesses the underlying PyTorch model from the vLLM engine.</li> <li>Registers a simple forward hook on a specific layer.</li> <li>Runs inference using <code>llm.generate()</code>.</li> <li>Verifies that the hook was executed during inference.</li> <li>Removes the hook and verifies it is no longer active.</li> </ul> <p>Note: This test requires a GPU environment with CUDA available and vLLM installed. For multi-GPU testing, set the <code>CUDA_VISIBLE_DEVICES</code> environment variable (e.g., <code>CUDA_VISIBLE_DEVICES=0,1</code>) before running the test. The test will automatically use the specified number of GPUs for tensor parallelism (<code>tensor_parallel_size</code>).</p>"},{"location":"code_readme/neuro_manipulation/tests/#test_vllm_hook_modificationpy","title":"<code>test_vllm_hook_modification.py</code>","text":""},{"location":"code_readme/neuro_manipulation/tests/#test-vllm-hook-output-modification-via-rpc","title":"Test: VLLM Hook Output Modification via RPC","text":"<p>This test script (<code>test_vllm_hook_modification.py</code>) verifies the ability to register PyTorch forward hooks onto specific layers of a model running within vLLM worker processes and modify the output of those layers. This is achieved using vLLM's <code>collective_rpc</code> mechanism.</p>"},{"location":"code_readme/neuro_manipulation/tests/#purpose","title":"Purpose","text":"<p>The primary goal is to demonstrate that: 1.  A hook function can be successfully registered onto a target layer (e.g., the first decoder block) across all tensor-parallel workers using RPC. 2.  This hook function can intercept the layer's forward pass output. 3.  The hook function can modify the output tensor (in this case, by zeroing it out). 4.  The modification to the intermediate layer's output has a tangible effect on the final generated text produced by the model.</p>"},{"location":"code_readme/neuro_manipulation/tests/#how-it-works","title":"How it Works","text":"<ol> <li>Initialization: An LLM instance is created using vLLM, potentially with tensor parallelism (<code>tensor_parallel_size &gt; 1</code>).</li> <li>Baseline Generation: The script first generates text for a given prompt without any hooks active. This serves as a baseline. <code>temperature=0.0</code> is used for deterministic output.</li> <li>Hook Function (<code>hook_fn_modify_output_global</code>): A global Python function is defined. This function:<ul> <li>Accepts the standard PyTorch hook arguments (<code>module</code>, <code>args</code>, <code>output</code>).</li> <li>Identifies the main output tensor (handling cases where the layer returns a tuple).</li> <li>Logs information about the tensor (shape, dtype, device).</li> <li>Modifies the tensor by creating a new tensor of zeros with the same properties (<code>torch.zeros_like</code>).</li> <li>Logs completion and returns the modified tensor (or reconstructed tuple).</li> </ul> </li> <li>RPC Registration (<code>_register_hook_on_worker_rpc</code>):<ul> <li>A helper function <code>_register_hook_on_worker_rpc</code> is defined to run on each worker via RPC.</li> <li>This function accesses the worker's local model instance (<code>worker_self.model_runner.model</code>).</li> <li>It uses <code>ModelLayerDetector</code> to find the layers of the model.</li> <li>It registers the <code>hook_fn_modify_output_global</code> to the specified <code>target_layer_index</code> (e.g., index 0).</li> <li>The main process calls <code>llm.llm_engine.collective_rpc(_register_hook_on_worker_rpc, args=(target_layer_index, hook_fn_modify_output_global))</code> to execute registration on all workers.</li> </ul> </li> <li>Modified Generation: The script runs generation again with the same prompt and sampling parameters, but now the hook is active.</li> <li>Verification:<ul> <li>The test asserts that the RPC call reported success on at least one worker.</li> <li>Crucially, it asserts that the text generated with the hook is different from the baseline text generated without the hook (<code>assertNotEqual</code>).</li> <li>Extensive logging is included in the hook and the test itself to aid debugging. Look for <code>*** MODIFY HOOK EXECUTING ***</code> messages in the logs from the workers.</li> </ul> </li> <li>Cleanup: Resources (LLM object) are deleted, and CUDA cache is cleared between test runs for different models.</li> </ol>"},{"location":"code_readme/neuro_manipulation/tests/#running-the-test","title":"Running the Test","text":"<p>Ensure you have the necessary dependencies (vLLM, PyTorch, etc.) installed in your environment (e.g., <code>conda activate llm</code>).</p> <pre><code># Activate your environment if needed\n# conda activate llm\n\n# Run the specific test file\npython -m unittest neuro_manipulation.tests.test_vllm_hook_modification\n</code></pre>"},{"location":"code_readme/neuro_manipulation/tests/#requirements","title":"Requirements","text":"<ul> <li>vLLM installed.</li> <li>PyTorch installed.</li> <li>Access to CUDA GPU(s). The test skips if <code>CUDA_VISIBLE_DEVICES</code> is not set.</li> <li>The <code>neuro_manipulation</code> package (containing <code>ModelLayerDetector</code>) available in the Python path.</li> </ul>"},{"location":"code_readme/neuro_manipulation/tests/#running-tests","title":"Running Tests","text":"<p>To run all tests in this directory, navigate to the project root and use the <code>unittest</code> discovery mechanism:</p> <pre><code>python -m unittest discover neuro_manipulation/tests/\n</code></pre> <p>To run a specific test file (e.g., the vLLM hook test):</p> <pre><code>python -m unittest neuro_manipulation.tests.test_vllm_hook_registration\n</code></pre> <p>To run a specific test class within a file:</p> <pre><code>python -m unittest neuro_manipulation.tests.test_vllm_hook_registration.TestVLLMHookRegistration\n</code></pre> <p>To run a specific test method within a class: <pre><code>python -m unittest neuro_manipulation.tests.test_vllm_hook_registration.TestVLLMHookRegistration.test_vllm_forward_hook\n</code></pre></p>"},{"location":"reference/emotion_analysis/","title":"Emotion Expression Analysis","text":"<p>This document provides information about the emotion expression analysis in rationales.</p>"},{"location":"reference/emotion_analysis/#overview","title":"Overview","text":"<p>The emotion expression analysis examines if the rationales in experiment results express the emotions they were assigned and investigates correlations with specific categories.</p>"},{"location":"reference/emotion_analysis/#key-features","title":"Key Features","text":"<ul> <li>Uses GPT-4o-mini for emotion detection in text</li> <li>Parallel Processing for significantly faster analysis of large datasets</li> <li>Provides statistical analysis of emotion expression rates by category</li> <li>Generates visualizations to compare expression rates</li> <li>Exports detailed results for further analysis</li> </ul>"},{"location":"reference/emotion_analysis/#inputs","title":"Inputs","text":"<ul> <li>Input Data Format: Describe the expected format of the input data that <code>result_analysis.rational_analysis</code> processes. (e.g., CSV/JSON file path, specific columns/fields expected).</li> <li>Example Input: (Optional, but helpful) A small snippet or description of an example input.</li> </ul>"},{"location":"reference/emotion_analysis/#outputs","title":"Outputs","text":"<ul> <li>Generated Files: Detail the files generated by the script.</li> <li><code>emotion_analysis_results.json</code>: (Describe structure and content)</li> <li><code>emotion_comparison_results.json</code>: (Describe structure and content, if different)</li> <li>Visualization files (e.g., <code>anger_vs_neutral_expression.png</code>): (Describe what they represent)</li> <li>Output Format/Schema: For JSON/CSV files, provide a brief schema or example of the data structure.</li> </ul>"},{"location":"reference/emotion_analysis/#performance-optimization","title":"Performance Optimization","text":"<p>The analysis script uses parallel processing to significantly improve performance:</p> <ul> <li>Processes multiple items concurrently using thread pooling (default workers: TBD, configurable).</li> <li>Implements smart rate limiting to avoid API throttling (default rate limit: TBD, configurable).</li> <li>Displays a progress bar for real-time feedback.</li> <li>Configurable performance parameters (workers, rate limits) - see Detailed Configuration below.</li> </ul>"},{"location":"reference/emotion_analysis/#data-size-control","title":"Data Size Control","text":"<p>For testing or limited analysis, the script can be configured to analyze only a subset of the data:</p> <ul> <li>By default, processes only the first 100 items (configurable).</li> <li>Easily adjustable limit by modifying a single line of code in <code>result_analysis.rational_analysis</code> (specify which line or if there's a parameter).</li> <li>Useful for preliminary analysis or when testing new features.</li> </ul>"},{"location":"reference/emotion_analysis/#detailed-configuration-customization","title":"Detailed Configuration &amp; Customization","text":"<ul> <li>Command-line Arguments: (If <code>result_analysis.rational_analysis</code> accepts any CLI arguments for configuration, list them here).</li> <li>Configuration File: (If the script uses a configuration file, describe its format and key options).</li> <li>Performance Parameters: </li> <li><code>num_workers</code>: (Describe how to set the number of parallel workers, e.g., script variable, CLI argument).</li> <li><code>rate_limit_per_minute</code>: (Describe how to set the API rate limit, e.g., script variable, CLI argument).</li> <li>Other Customizations: (Any other ways the script can be customized).</li> </ul>"},{"location":"reference/emotion_analysis/#running-the-analysis","title":"Running the Analysis","text":"<p>To run the analysis:</p> <pre><code># Activate conda environment\nconda activate llm\n\n# Run the script\npython -m result_analysis.rational_analysis\n</code></pre> <p>See the detailed documentation for more information about performance tuning, data size control, requirements, outputs, and customization options. </p>"},{"location":"reference/experiment_report_naming/","title":"Experiment Report Naming","text":""},{"location":"reference/experiment_report_naming/#overview","title":"Overview","text":"<p>This document describes the naming convention for experiment reports generated by the <code>ExperimentSeriesRunner</code>. Reports are stored as JSON files that track the status of multiple experiments in a series.</p>"},{"location":"reference/experiment_report_naming/#naming-convention","title":"Naming Convention","text":"<p>Experiment report files follow this naming pattern: <pre><code>&lt;base_dir&gt;/&lt;experiment_name&gt;_&lt;timestamp&gt;/experiment_report.json\n</code></pre></p> <p>Where: - <code>base_dir</code>: The base directory specified in the experiment config - <code>experiment_name</code>: The name from the experiment config file (preferred) or the series name provided via CLI argument (fallback) - <code>timestamp</code>: A timestamp in the format YYYYMMDD_HH</p>"},{"location":"reference/experiment_report_naming/#priority-order","title":"Priority Order","text":"<p>The report directory name is determined with the following priority:</p> <ol> <li>Use <code>experiment.name</code> from the config file if available</li> <li>Fall back to the <code>series_name</code> provided via CLI argument if available</li> <li>Use \"experiment_series\" as the default if nothing else is specified</li> </ol>"},{"location":"reference/experiment_report_naming/#example","title":"Example","text":"<p>Given: - Config file with <code>experiment.name = \"Emotional_Response_Effects\"</code> - CLI command: <code>python -m neuro_manipulation.run_experiment_series --config config.yaml --name \"CLI_Series_Name\"</code></p> <p>The report will be stored at: <pre><code>&lt;base_dir&gt;/Emotional_Response_Effects_20250210_163355/experiment_report.json\n</code></pre></p> <p>In this example, the name from the config file takes precedence over the CLI argument.</p>"},{"location":"reference/experiment_report_naming/#relation-to-individual-experiment-outputs","title":"Relation to Individual Experiment Outputs","text":"<p>This naming convention ensures that experiment reports are stored consistently with individual experiment outputs from the <code>EmotionGameExperiment</code> class, which also uses the experiment name from the config file in its directory structure.</p>"},{"location":"reference/experiment_report_naming/#changes-in-v021","title":"Changes in v0.2.1","text":"<p>Previously, experiment reports were stored using only the <code>series_name</code> argument, which led to inconsistencies with the individual experiment output directories. This has been fixed to prioritize the experiment name from the config file to ensure consistent directory structures. </p>"},{"location":"reference/experiment_series_README/","title":"Experiment Series Pipeline","text":"<p>This document explains how to use the experiment series pipeline for running multiple experiments with different combinations of games and models.</p>"},{"location":"reference/experiment_series_README/#overview","title":"Overview","text":"<p>The experiment series pipeline allows you to run a permutation and combination of games and models in a single command. The pipeline has the following features:</p> <ol> <li>Creates a new result base folder for the series of experiments.</li> <li>Maintains the same structure for individual experiment results as the current system.</li> <li>Handles failures in sub-experiments gracefully, continuing with the next experiment.</li> <li>Generates a completeness report that is updated in real-time.</li> <li>Supports graceful shutdown (Ctrl+C) and experiment resumption.</li> </ol>"},{"location":"reference/experiment_series_README/#configuration","title":"Configuration","text":"<p>Create a configuration file similar to <code>config/experiment_series_config.yaml</code>. The key sections to configure are:</p> <pre><code>experiment:\n  name: \"Multi_Game_Model_Experiment_Series\"\n\n  # List of games to run experiments with\n  games:\n    - \"Prisoners_Dilemma\"\n    - \"Escalation_Game\"\n    - \"Ultimatum_Game\"\n\n  # List of models to run experiments with\n  models:\n    - \"meta-llama/Llama-3.1-8B-Instruct\"\n    - \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n\n  # Rest of the configuration...\n</code></pre> <p>The pipeline will run experiments for all combinations of games and models specified.</p>"},{"location":"reference/experiment_series_README/#running-the-pipeline","title":"Running the Pipeline","text":"<p>To run the experiment series:</p> <pre><code># First activate the conda environment\nconda activate llm\n\n# Run the experiment series\npython -m neuro_manipulation.run_experiment_series --config config/experiment_series_config.yaml\n</code></pre> <p>Optional arguments: - <code>--name</code>: Custom name for the experiment series - <code>--resume</code>: Resume a previously interrupted experiment series</p>"},{"location":"reference/experiment_series_README/#output-structure","title":"Output Structure","text":"<p>The results will be organized in the following structure:</p> <pre><code>results/\n\u2514\u2500\u2500 ExperimentSeries/\n    \u2514\u2500\u2500 Multi_Game_Model_Experiment_Series_20250210_163355/\n        \u251c\u2500\u2500 experiment_report.json\n        \u251c\u2500\u2500 Prisoners_Dilemma_Llama-3.1-8B-Instruct_20250210_163355/\n        \u2502   \u251c\u2500\u2500 exp_config.yaml\n        \u2502   \u251c\u2500\u2500 exp_results.csv\n        \u2502   \u251c\u2500\u2500 exp_results.json\n        \u2502   \u2514\u2500\u2500 stats_analysis.json\n        \u251c\u2500\u2500 Escalation_Game_Llama-3.1-8B-Instruct_20250210_163455/\n        \u2502   \u2514\u2500\u2500 ...\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"reference/experiment_series_README/#experiment-report","title":"Experiment Report","text":"<p>The <code>experiment_report.json</code> file contains the status of all experiments in the series:</p> <pre><code>{\n  \"last_updated\": \"2025-02-10T16:34:55\",\n  \"experiments\": {\n    \"Prisoners_Dilemma_Llama-3.1-8B-Instruct\": {\n      \"game_name\": \"Prisoners_Dilemma\",\n      \"model_name\": \"meta-llama/Llama-3.1-8B-Instruct\",\n      \"status\": \"completed\",\n      \"start_time\": \"2025-02-10T16:33:55\",\n      \"end_time\": \"2025-02-10T16:34:55\",\n      \"error\": null,\n      \"output_dir\": \"results/ExperimentSeries/Prisoners_Dilemma_Llama-3.1-8B-Instruct_20250210_163355\",\n      \"exp_id\": \"Prisoners_Dilemma_Llama-3.1-8B-Instruct\"\n    },\n    \"Escalation_Game_Llama-3.1-8B-Instruct\": {\n      \"status\": \"running\",\n      \"...\": \"...\"\n    }\n  }\n}\n</code></pre>"},{"location":"reference/experiment_series_README/#resuming-experiments","title":"Resuming Experiments","text":"<p>If an experiment series is interrupted (either by an error or by user intervention with Ctrl+C), you can resume it:</p> <pre><code>python -m neuro_manipulation.run_experiment_series --config config/experiment_series_config.yaml --resume\n</code></pre> <p>This will skip completed experiments and retry failed or pending ones.</p>"},{"location":"reference/experiment_series_README/#report-naming-convention","title":"Report Naming Convention","text":"<p>The experiment report is stored in a directory named using the experiment name from the config file rather than the series name from the command line argument. This ensures consistency with individual experiment output directories.</p> <p>For detailed information about the naming convention, see Experiment Report Naming.</p>"},{"location":"reference/experiment_series_README/#validation-rules","title":"Validation Rules","text":"<p>The experiment series runner performs several validations before running experiments:</p> <ol> <li>Previous Actions Length: The <code>previous_actions_length</code> parameter in game config must be set to 0. This ensures that sequential game experiments are properly set up. If this validation fails, the runner will raise a ValueError with a descriptive message. </li> </ol>"},{"location":"reference/game_tree/","title":"Deprecated","text":""},{"location":"reference/game_tree/#game-tree-data-structure","title":"Game Tree Data Structure","text":"<p>This document explains the game tree data structure used to represent payoff matrices for both simultaneous and sequential games.</p>"},{"location":"reference/game_tree/#overview","title":"Overview","text":"<p>The game tree structure provides a unified way to represent game-theoretic scenarios in a flexible, tree-based format. This approach allows us to:</p> <ol> <li>Represent both simultaneous and sequential games using a common data structure</li> <li>Generate natural language descriptions of game payoffs</li> <li>Support complex game scenarios with multiple decision points and players</li> </ol>"},{"location":"reference/game_tree/#data-structure","title":"Data Structure","text":"<p>The game tree consists of three types of nodes:</p>"},{"location":"reference/game_tree/#1-terminalnode","title":"1. TerminalNode","text":"<p>Represents the payoffs at the end of a game path.</p> <pre><code>@dataclass\nclass TerminalNode:\n    payoffs: Tuple[float, ...]  # e.g., (3, 3) for (p1, p2)\n</code></pre>"},{"location":"reference/game_tree/#2-decisionnode","title":"2. DecisionNode","text":"<p>Represents a sequential move where one player makes a decision.</p> <pre><code>@dataclass\nclass DecisionNode:\n    player: str  # e.g., \"p1\" or \"Alice\"\n    actions: Dict[str, 'GameNode']  # maps action -&gt; next node\n</code></pre>"},{"location":"reference/game_tree/#3-simultaneousnode","title":"3. SimultaneousNode","text":"<p>Represents a simultaneous move where multiple players choose actions at once.</p> <pre><code>@dataclass\nclass SimultaneousNode:\n    players: Tuple[str, ...]  # e.g., (\"p1\", \"p2\") or (\"Alice\", \"Bob\")\n    actions: Dict[Tuple[str, ...], 'GameNode']  # maps (action1, action2, ...) -&gt; next node\n</code></pre>"},{"location":"reference/game_tree/#payoffmatrix-class","title":"PayoffMatrix Class","text":"<p>The <code>PayoffMatrix</code> class encapsulates a game tree and provides methods to:</p> <ol> <li>Create a PayoffMatrix from different dictionary formats</li> <li>Generate natural language descriptions of the game</li> </ol> <pre><code>class PayoffMatrix:\n    def __init__(self, game_tree: GameNode, name: str = \"\", description: str = \"\"):\n        self.game_tree = game_tree\n        self.name = name\n        self.description = description\n\n    @staticmethod\n    def from_simultaneous_dict(payoff_dict): ...\n\n    @staticmethod\n    def from_sequential_dict(seq_dict, players=None): ...\n\n    def describe_game(self): ...\n\n    def get_natural_language_description(self, participants: Optional[List[str]] = None): ...\n</code></pre>"},{"location":"reference/game_tree/#example-usage","title":"Example Usage","text":""},{"location":"reference/game_tree/#simultaneous-game-prisoners-dilemma","title":"Simultaneous Game (Prisoner's Dilemma)","text":"<pre><code>prisoners_dilemma = {\n    \"p1\": {\n        \"cooperate\": {\"p2_cooperate\": 3, \"p2_defect\": 0},\n        \"defect\": {\"p2_cooperate\": 5, \"p2_defect\": 1},\n    },\n    \"p2\": {\n        \"cooperate\": {\"p1_cooperate\": 3, \"p1_defect\": 0},\n        \"defect\": {\"p1_cooperate\": 5, \"p1_defect\": 1},\n    },\n}\n\npd_matrix = PayoffMatrix.from_simultaneous_dict(prisoners_dilemma, name=\"Prisoner's Dilemma\")\nprint(pd_matrix.get_natural_language_description())\n</code></pre>"},{"location":"reference/game_tree/#sequential-game-ultimatum-game","title":"Sequential Game (Ultimatum Game)","text":"<pre><code>ultimatum_game = {\n    \"fair_split\": {\n        \"accept\": [5, 5],\n        \"reject\": [0, 0],\n    },\n    \"unfair_split\": {\n        \"accept\": [8, 2],\n        \"reject\": [0, 0],\n    },\n}\n\nug_matrix = PayoffMatrix.from_sequential_dict(ultimatum_game, players=[\"proposer\", \"responder\"])\nprint(ug_matrix.get_natural_language_description())\n</code></pre>"},{"location":"reference/game_tree/#integration-with-gamescenario","title":"Integration with GameScenario","text":"<p>The <code>GameScenario</code> class has been updated to support both the traditional dictionary-based payoff matrices and the new <code>PayoffMatrix</code> class. This provides backward compatibility while enabling more complex game structures.</p> <p>When a <code>PayoffMatrix</code> instance is provided, the natural language description is generated directly via <code>payoff_matrix.get_natural_language_description(participants=...)</code>, using the participant names from the scenario. </p>"},{"location":"reference/model_download_management/","title":"Model Download and Management","text":""},{"location":"reference/model_download_management/#overview","title":"Overview","text":"<p>The ExperimentSeriesRunner has been enhanced with automatic model checking and downloading capabilities. This feature ensures that models required for experiments are downloaded before the experiment starts, improving the reliability of batch experiments.</p>"},{"location":"reference/model_download_management/#how-it-works","title":"How it Works","text":"<p>The system checks for model existence in two locations: 1. HuggingFace's default cache location (<code>~/.cache/huggingface/hub/</code>) 2. An alternative location in the parent directory (<code>../huggingface_models</code>)</p> <p>Path Structure Note: - When storing models in the alternative location (<code>../huggingface_models</code>), the directory structure mirrors the HuggingFace organization/model format. For example, the model <code>Qwen/Qwen2.5-7B-Instruct</code> will be stored at <code>../huggingface_models/Qwen/Qwen2.5-7B-Instruct</code>. - This ensures that models from different organizations or with similar names are kept separate and organized, just as they are on HuggingFace.</p> <p>If a model is not found in either location, it will be downloaded to the alternative location using the <code>huggingface-cli</code> command-line tool, which is more reliable and efficient than the Python API, especially for large models.</p>"},{"location":"reference/model_download_management/#implementation-details","title":"Implementation Details","text":""},{"location":"reference/model_download_management/#model-checking-logic","title":"Model Checking Logic","text":"<p>The core functionality is implemented in the <code>_check_model_existence</code> method:</p> <pre><code>def _check_model_existence(self, model_name: str) -&gt; bool:\n    \"\"\"\n    Check if the model exists in either ~/.cache/huggingface/hub/ or ../huggingface_models.\n    If not, download it to ../huggingface_models.\n\n    Args:\n        model_name: The name of the model to check\n\n    Returns:\n        bool: True if model exists or was successfully downloaded, False otherwise\n    \"\"\"\n    # Implementation details...\n</code></pre>"},{"location":"reference/model_download_management/#features","title":"Features:","text":"<ol> <li>Local Path Support: Models specified with absolute paths (starting with <code>/</code>) are assumed to be local and skipped from checking.</li> <li>Path Detection: For HuggingFace models, it correctly handles the path structure used by HuggingFace, including organization and model name.</li> <li>Command-line Downloads: Uses <code>huggingface-cli download</code> with <code>HF_HUB_ENABLE_HF_TRANSFER=1</code> for faster, more reliable downloads.</li> <li>Real-time Progress: Streams download progress to the log in real time.</li> <li>Failure Handling: If a model fails to download, the experiment with that model is marked as failed but doesn't stop the entire series.</li> </ol>"},{"location":"reference/model_download_management/#integration-in-experiment-series-runner","title":"Integration in Experiment Series Runner","text":"<p>The model checking is integrated at two key points:</p> <ol> <li>Pre-check all models: At the start of the experiment series, all models are checked to pre-download them.</li> <li>Per-experiment check: Before each individual experiment, the model is checked again to ensure it's available.</li> </ol>"},{"location":"reference/model_download_management/#usage","title":"Usage","text":"<p>No additional configuration is needed. The ExperimentSeriesRunner will automatically check for models and download them as needed.</p>"},{"location":"reference/model_download_management/#download-command","title":"Download Command","text":"<p>The system uses this command format for downloads:</p> <pre><code>HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download [MODEL_NAME] --local-dir [TARGET_DIR]\n</code></pre> <p>For example: <pre><code>HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir ../huggingface_models/Qwen/Qwen2.5-7B-Instruct\n</code></pre></p>"},{"location":"reference/model_download_management/#testing","title":"Testing","text":"<p>Unit tests for this functionality are available in <code>neuro_manipulation/tests/test_model_check.py</code>. The tests cover:</p> <ol> <li>Local model path detection</li> <li>Existing model detection</li> <li>Model download process</li> <li>Handling of download failures</li> </ol>"},{"location":"reference/model_download_management/#notes","title":"Notes","text":"<ul> <li>The download process uses the optimized Hugging Face transfer protocol via the environment variable <code>HF_HUB_ENABLE_HF_TRANSFER=1</code>.</li> <li>This approach is generally faster and more reliable than using the Python API directly, especially for large models.</li> <li>If a model fails to download, the experiment involving that model will be marked as failed, but other experiments in the series will continue running. </li> </ul>"},{"location":"reference/model_layer_detector/","title":"Model Layer Detector","text":""},{"location":"reference/model_layer_detector/#overview","title":"Overview","text":"<p>The <code>ModelLayerDetector</code> is a utility class that automatically detects transformer layers in any model architecture without hardcoding model-specific paths. It's especially useful when working with multiple different model architectures or when you want to build model-agnostic tools.</p>"},{"location":"reference/model_layer_detector/#key-features","title":"Key Features","text":"<ul> <li>Model-Agnostic: Works with any transformer-based model architecture (e.g., GPT-2, OPT, Llama, Mistral, ChatGLM, RWKV, Mamba, xLSTM, and other HuggingFace or custom transformer architectures).</li> <li>Zero Configuration: No need to specify model-specific paths or patterns.</li> <li>Flexible Detection: Uses intelligent heuristics and breadth-first search to identify transformer layers.</li> <li>Handles Nesting: Efficiently traverses deeply nested model structures, common in frameworks like vLLM.</li> <li>Robust Fallbacks: Includes fallback mechanisms if standard patterns are not found.</li> </ul>"},{"location":"reference/model_layer_detector/#api-reference","title":"API Reference","text":""},{"location":"reference/model_layer_detector/#modellayerdetectorget_model_layersmodel","title":"<code>ModelLayerDetector.get_model_layers(model)</code>","text":"<p>Find transformer layers in a model using breadth-first search traversal.</p> <p>Parameters: - <code>model</code> (torch.nn.Module): Any PyTorch model.</p> <p>Returns: - <code>torch.nn.ModuleList</code>: The detected transformer layers.</p> <p>Raises: - <code>ValueError</code>: If no transformer layers could be detected.</p>"},{"location":"reference/model_layer_detector/#modellayerdetectornum_layersmodel","title":"<code>ModelLayerDetector.num_layers(model)</code>","text":"<p>Returns the number of transformer layers detected in the model. This is a convenience method that calls <code>len(ModelLayerDetector.get_model_layers(model))</code>.</p> <p>Parameters: - <code>model</code> (torch.nn.Module): Any PyTorch model.</p> <p>Returns: - <code>int</code>: The number of detected transformer layers.</p>"},{"location":"reference/model_layer_detector/#modellayerdetectorprint_model_structuremodel-max_depth3","title":"<code>ModelLayerDetector.print_model_structure(model, max_depth=3)</code>","text":"<p>Print the structure of a PyTorch model to help with debugging.</p> <p>Parameters: - <code>model</code> (torch.nn.Module): Any PyTorch model. - <code>max_depth</code> (int, optional): Maximum depth to print. Defaults to 3.</p>"},{"location":"reference/model_layer_detector/#how-it-works-implementation-details","title":"How It Works / Implementation Details","text":"<p>The <code>ModelLayerDetector</code> employs a sophisticated strategy to identify transformer layers:</p> <ol> <li>Breadth-First Search (BFS) Traversal: The detector explores the model's module hierarchy level by level using BFS. This ensures that layers closer to the model root are considered first.</li> <li>Transformer Layer Identification:<ul> <li>It defines characteristics of a transformer layer, such as the presence of attention components (e.g., attributes named <code>attention</code>, <code>self_attn</code>, <code>attn</code>) or other common transformer parts like <code>mlp</code>, <code>ffn</code>, <code>layernorm</code>.</li> <li>It checks <code>torch.nn.ModuleList</code> instances to see if they contain a sequence of such transformer-like modules.</li> </ul> </li> <li>Candidate Prioritization:<ul> <li>The detector prioritizes <code>nn.ModuleList</code> instances that are explicitly named <code>layers</code> (e.g., <code>model.layers</code>).</li> <li>Among candidates, those with shorter module paths (i.e., less deeply nested) are preferred.</li> </ul> </li> <li>Fallback Mechanism: If the primary heuristics don't identify layers, the detector falls back to searching for any <code>nn.ModuleList</code> where all contained modules are of the same class type. This can help with less conventionally structured models.</li> <li>Visited Module Tracking: To handle potential circular references in model architectures and improve efficiency, the detector keeps track of already visited modules during traversal.</li> </ol> <p>This multi-faceted approach makes the detector robust to diverse model architectures and common naming conventions.</p>"},{"location":"reference/model_layer_detector/#examples","title":"Examples","text":""},{"location":"reference/model_layer_detector/#basic-usage","title":"Basic Usage","text":"<pre><code>from transformers import AutoModel\nfrom neuro_manipulation.model_layer_detector import ModelLayerDetector\n\n# Load any model\nmodel = AutoModel.from_pretrained(\"gpt2\")\n\n# Automatically detect its layers\nlayers = ModelLayerDetector.get_model_layers(model)\nnum_layers = ModelLayerDetector.num_layers(model)\n\nprint(f\"Found {len(layers)} transformer layers (also confirmed by num_layers: {num_layers})\")\n</code></pre>"},{"location":"reference/model_layer_detector/#debugging-model-structure","title":"Debugging Model Structure","text":"<pre><code># Print the model structure to understand its hierarchy\nModelLayerDetector.print_model_structure(model)\n</code></pre>"},{"location":"reference/model_layer_detector/#working-with-different-model-architectures","title":"Working with Different Model Architectures","text":"<p>The detector is designed to be model-agnostic: <pre><code>from transformers import AutoModel, AutoModelForCausalLM\nfrom neuro_manipulation.model_layer_detector import ModelLayerDetector # Ensure correct import\n\n# Example with a Llama-like model (replace with actual loading if needed)\n# model_llama = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\") \n# layers_llama = ModelLayerDetector.get_model_layers(model_llama)\n# print(f\"Llama-like model: {len(layers_llama)} layers\")\n\n# ChatGLM models\n# Assuming 'THUDM/glm-4-9b' is available and loads correctly\n# chatglm = AutoModel.from_pretrained(\"THUDM/glm-4-9b\", trust_remote_code=True)\n# chatglm_layers = ModelLayerDetector.get_model_layers(chatglm)\n# print(f\"ChatGLM model: {len(chatglm_layers)} layers\")\n\n# RWKV models\n# rwkv = AutoModelForCausalLM.from_pretrained(\"BlinkDL/rwkv-4-raven\", trust_remote_code=True)\n# rwkv_layers = ModelLayerDetector.get_model_layers(rwkv)\n# print(f\"RWKV model: {len(rwkv_layers)} layers\")\n</code></pre> (Note: The above examples for specific architectures might require the respective models to be downloaded and accessible in your environment.)</p>"},{"location":"reference/model_layer_detector/#integration-with-vllm","title":"Integration with vLLM","text":"<p>The <code>ModelLayerDetector</code> is also designed to work with vLLM's potentially nested model structure:</p> <p><pre><code># Example usage with vLLM (conceptual, requires vLLM setup)\n# from neuro_manipulation.model_layer_detector import ModelLayerDetector\n# from vllm import LLM\n\n# llm = LLM(model=\"meta-llama/Llama-3.1-8B-Instruct\")\n# Ensure you access the correct underlying PyTorch model from the vLLM LLM object\n# This path might vary based on vLLM version and setup\n# model_vllm_runner = llm.llm_engine.model_executor.driver_worker.model_runner.model \n# model_layers_vllm = ModelLayerDetector.get_model_layers(model_vllm_runner)\n\n# print(f\"vLLM (Llama-3.1-8B-Instruct) has: {len(model_layers_vllm)} layers\")\n# For Llama models, this often corresponds to model.model.layers\n</code></pre> This capability is crucial for representation engineering techniques that need to dynamically access or modify model layers within a vLLM serving environment.</p>"},{"location":"reference/model_layer_detector/#when-to-use","title":"When to Use","text":"<p>This utility is particularly useful when:</p> <ol> <li>Working with multiple different model architectures.</li> <li>Building model-agnostic tools and pipelines for layer manipulation or analysis.</li> <li>Exploring new or custom model architectures without prior knowledge of their structure.</li> <li>Avoiding hardcoded model-specific layer paths that can break with model updates or variations.</li> </ol>"},{"location":"reference/model_layer_detector/#testing","title":"Testing","text":"<p>For detailed information about testing the <code>ModelLayerDetector</code> with various models, including standard HuggingFace models, custom architectures, and vLLM-hosted models, please refer to the test documentation in the <code>neuro_manipulation/tests/</code> directory. The tests verify compatibility with:</p> <ol> <li>Small Standard Models: e.g., GPT-2, OPT-125M.</li> <li>Specialized Architectures: e.g., ChatGLM, RWKV.</li> <li>Custom Transformer Models: Demonstrating adaptability.</li> <li>vLLM Integration: Specifically testing layer detection within models loaded via vLLM.</li> <li>Hook Registration Compatibility: Ensuring layers found can be used for PyTorch hook registration, crucial for some representation engineering tasks. </li> </ol>"},{"location":"reference/payoff_matrices/","title":"PayoffMatrix Documentation","text":"<p>The <code>PayoffMatrix</code> class is a data structure for representing game theory payoff matrices in a unified way for both simultaneous and sequential games.</p>"},{"location":"reference/payoff_matrices/#key-classes","title":"Key Classes","text":""},{"location":"reference/payoff_matrices/#payoffleaf","title":"PayoffLeaf","text":"<p>The <code>PayoffLeaf</code> class represents a single outcome in a game with associated payoffs:</p> <pre><code>PayoffLeaf(actions=(\"cooperate\", \"cooperate\"), payoffs=(3, 3))\n</code></pre> <ul> <li><code>actions</code>: Tuple of actions taken by each player (player1_action, player2_action)</li> <li><code>payoffs</code>: Tuple of payoffs received by each player (player1_payoff, player2_payoff)</li> <li><code>ranks</code>: Optional tuple of ranks for this outcome from each player's perspective (e.g., for manual annotation or specific analyses; not auto-populated by <code>PayoffMatrix</code>).</li> </ul>"},{"location":"reference/payoff_matrices/#payoffmatrix","title":"PayoffMatrix","text":"<p>The <code>PayoffMatrix</code> class represents the complete payoff structure of a game:</p> <pre><code>matrix = PayoffMatrix(\n    player_num=2,\n    payoff_leaves=[\n        PayoffLeaf(actions=(\"cooperate\", \"cooperate\"), payoffs=(3, 3)),\n        PayoffLeaf(actions=(\"cooperate\", \"defect\"), payoffs=(0, 5)),\n        PayoffLeaf(actions=(\"defect\", \"cooperate\"), payoffs=(5, 0)),\n        PayoffLeaf(actions=(\"defect\", \"defect\"), payoffs=(1, 1)),\n    ]\n)\n</code></pre> <ul> <li><code>player_num</code>: Number of players in the game</li> <li><code>payoff_leaves</code>: List of PayoffLeaf objects representing all possible outcomes</li> <li><code>ordered_payoff_leaves</code>: Dictionary mapping player indices to their ordered preferences (calculated automatically)</li> </ul>"},{"location":"reference/payoff_matrices/#features","title":"Features","text":""},{"location":"reference/payoff_matrices/#preference-ordering","title":"Preference Ordering","text":"<p>The <code>build_ranks</code> validator automatically calculates each player's preference ordering among all possible outcomes. For each player, outcomes are sorted from highest to lowest payoff.</p>"},{"location":"reference/payoff_matrices/#human-readable-description","title":"Human-Readable Description","text":"<p>The <code>__str__</code> method provides a textual description of the game, including: - Basic descriptions of all possible outcomes and their payoffs</p> <p>Example output: <pre><code>Game Payoffs:\nWhen player 1 chooses 'cooperate' and player 2 chooses 'cooperate', player 1 gets 3 and player 2 gets 3.\nWhen player 1 chooses 'cooperate' and player 2 chooses 'defect', player 1 gets 0 and player 2 gets 5.\nWhen player 1 chooses 'defect' and player 2 chooses 'cooperate', player 1 gets 5 and player 2 gets 0.\nWhen player 1 chooses 'defect' and player 2 chooses 'defect', player 1 gets 1 and player 2 gets 1.\n</code></pre></p>"},{"location":"reference/payoff_matrices/#usage","title":"Usage","text":"<p>To create a new game matrix:</p> <pre><code>game_matrix = PayoffMatrix(\n    player_num=2,\n    payoff_leaves=[\n        # List all possible outcomes with their payoffs\n        PayoffLeaf(actions=(\"action1\", \"action1\"), payoffs=(payoff1_1, payoff1_2)),\n        PayoffLeaf(actions=(\"action1\", \"action2\"), payoffs=(payoff2_1, payoff2_2)),\n        # ...\n    ]\n)\n\n# Get human-readable description\nprint(game_matrix)\n\n# Access ordered preferences for player 0 (first player)\nprint(game_matrix.ordered_payoff_leaves[0])\n</code></pre>"},{"location":"reference/prompt_format/","title":"Prompt Format System","text":""},{"location":"reference/prompt_format/#overview","title":"Overview","text":"<p>The prompt format system in this project provides a way to format prompts for various language models in a consistent way. The system supports different model formats including Llama-2, Llama-3, and Mistral.</p>"},{"location":"reference/prompt_format/#changes","title":"Changes","text":"<p>The prompt format system was updated to use the tokenizer's built-in <code>apply_chat_template</code> method instead of manually formatting prompts. This change ensures that prompts are formatted according to the official chat template defined by the model providers.</p>"},{"location":"reference/prompt_format/#classes","title":"Classes","text":""},{"location":"reference/prompt_format/#promptformat","title":"PromptFormat","text":"<p>The <code>PromptFormat</code> class is the main entry point for the prompt format system. It uses the tokenizer's <code>apply_chat_template</code> method to format prompts.</p> <pre><code>from transformers import AutoTokenizer\nfrom neuro_manipulation.prompt_formats import PromptFormat\n\n# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n\n# Create prompt format\nprompt_format = PromptFormat(tokenizer)\n\n# Format a prompt\nprompt = prompt_format.build(\n    \"You are a helpful assistant.\",\n    [\"Hello, how are you?\"],\n    [\"I'm doing well, thank you!\"]\n)\n</code></pre>"},{"location":"reference/prompt_format/#manualpromptformat","title":"ManualPromptFormat","text":"<p>The <code>ManualPromptFormat</code> class is the original implementation that manually formatted prompts. Used as the backup plan when huggingface tokenizer.apply_chat_format failed.</p>"},{"location":"reference/prompt_format/#model-specific-format-classes","title":"Model-specific Format Classes","text":"<p>The system also includes model-specific format classes that define the format for each model type:</p> <ul> <li><code>Llama2InstFormat</code>: Format for Llama-2 models</li> <li><code>Llama3InstFormat</code>: Format for Llama-3 models</li> <li><code>MistralInstFormat</code>: Format for Mistral models</li> <li><code>RWKVsFormat</code>: Format for RWKV models</li> </ul> <p>These classes are used as fallbacks in case the tokenizer's <code>apply_chat_template</code> method fails.</p>"},{"location":"reference/prompt_format/#integration-with-promptwrapper","title":"Integration with PromptWrapper","text":"<p>The <code>PromptFormat</code> class is designed to be used with the <code>PromptWrapper</code> class, which provides a higher-level API for generating prompts:</p> <pre><code>from neuro_manipulation.prompt_formats import PromptFormat\nfrom neuro_manipulation.prompt_wrapper import PromptWrapper\n\n# Initialize tokenizer and prompt format\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\nprompt_format = PromptFormat(tokenizer)\n\n# Create prompt wrapper\nwrapper = PromptWrapper(prompt_format)\n\n# Generate a prompt\nprompt = wrapper(\n    \"You are at a party\",\n    [\"Go talk to people\", \"Stay in a corner\"],\n    \"What should I do?\"\n)\n</code></pre>"},{"location":"reference/prompt_format/#testing","title":"Testing","text":"<p>Tests for the prompt format system are located in the <code>neuro_manipulation/tests</code> directory. They validate:</p> <ol> <li>Compatibility with different model formats</li> <li>Handling different numbers of messages</li> <li>Integration with the prompt wrapper system</li> </ol> <p>To run the tests:</p> <pre><code>python -m unittest neuro_manipulation/tests/test_prompt_format.py\npython -m unittest neuro_manipulation/tests/test_prompt_format_integration.py\n</code></pre>"},{"location":"reference/prompt_wrapper/","title":"Prompt Wrapper","text":"<p>The <code>PromptWrapper</code> class is a key component in the prompt formatting system that helps with the construction of prompts for specific use cases like game theory experiments.</p>"},{"location":"reference/prompt_wrapper/#overview","title":"Overview","text":"<p>The <code>PromptWrapper</code> class wraps a <code>PromptFormat</code> instance and provides a simplified interface for generating prompts with event descriptions and options. It handles the construction of system prompts and user messages in a consistent way.</p>"},{"location":"reference/prompt_wrapper/#class-hierarchy","title":"Class Hierarchy","text":"<ul> <li>PromptWrapper: Base wrapper that generates standard prompts.</li> <li>ReactionPromptWrapper: Specialization for prompting user reactions.</li> <li>GameReactPromptWrapper: Specialization for game theory experiments using a ReAct-style format.</li> </ul>"},{"location":"reference/prompt_wrapper/#usage","title":"Usage","text":"<pre><code>from transformers import AutoTokenizer\nfrom neuro_manipulation.prompt_formats import PromptFormat\nfrom neuro_manipulation.prompt_wrapper import PromptWrapper\n\n# Initialize tokenizer and prompt format\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\nprompt_format = PromptFormat(tokenizer)\n\n# Create prompt wrapper\nwrapper = PromptWrapper(prompt_format)\n\n# Generate a prompt\nevent = \"You are at a party\"\noptions = [\"Go talk to people\", \"Stay in a corner\"]\nuser_message = \"What should I do?\"\nprompt = wrapper(event, options, user_message)\n</code></pre>"},{"location":"reference/prompt_wrapper/#implementation-details","title":"Implementation Details","text":""},{"location":"reference/prompt_wrapper/#model-name-detection","title":"Model Name Detection","text":"<p>The <code>PromptWrapper</code> utilizes a <code>PromptFormat</code> instance, which is initialized with a tokenizer corresponding to a specific model. The <code>PromptFormat</code> object then handles model-specific formatting internally.</p> <pre><code>def __call__(self, event, options, user_messages):\n    # The self.prompt_format object (initialized with a model-specific tokenizer)\n    # handles the prompt building.\n    return self.prompt_format.build(self.system_prompt(event, options), self.user_messages(user_messages))\n</code></pre>"},{"location":"reference/prompt_wrapper/#system-prompt-formatting","title":"System Prompt Formatting","text":"<p>The system prompt is formatted using the following template:</p> <pre><code>system_prompt_format = 'You are an average American.'\n</code></pre> <p>For <code>GameReactPromptWrapper</code>, the template is:</p> <pre><code>system_prompt_format = \"You are Alice. You are in the following situation: {event}. \"\n</code></pre>"},{"location":"reference/prompt_wrapper/#options-formatting","title":"Options Formatting","text":"<p>Options are formatted with numbering:</p> <pre><code>Option 1. Go talk to people\nOption 2. Stay in a corner\n</code></pre>"},{"location":"reference/prompt_wrapper/#gamereactpromptwrapper-response-format","title":"GameReactPromptWrapper Response Format","text":"<p>The <code>GameReactPromptWrapper</code> includes instructions for the model to respond in a specific JSON format:</p> <pre><code>def format_instruction(self):\n    return f\"response in json format, with the following structure: {self.response_format.example()}\"\n</code></pre>"},{"location":"reference/prompt_wrapper/#integration-with-multiple-models","title":"Integration with Multiple Models","text":"<p>The wrapper works with multiple model architectures:</p> <ol> <li>Llama 2: <code>meta-llama/Llama-2-7b-chat-hf</code></li> <li>Llama 3: <code>meta-llama/Llama-3.1-8B-Instruct</code> </li> <li>Mistral: <code>mistralai/Mistral-7B-Instruct-v0.3</code></li> </ol> <p>Each model has its own chat template, which is applied by the underlying <code>PromptFormat</code> class.</p>"},{"location":"reference/prompt_wrapper/#testing","title":"Testing","text":"<p>The wrapper is tested in the integration tests:</p> <pre><code>python -m unittest neuro_manipulation.tests.test_prompt_format_integration\n</code></pre> <p>These tests verify that the wrapper correctly integrates with the prompt format and generates valid prompts for each supported model. </p>"},{"location":"reference/scenario_creation_graph/","title":"Scenario Creation Graph","text":"<p>This document explains the LangGraph-based scenario creation process for game theory experiments.</p>"},{"location":"reference/scenario_creation_graph/#overview","title":"Overview","text":"<p>The Scenario Creation Graph automates the process of creating realistic scenarios for game theory experiments. It uses LangGraph to orchestrate a multi-step workflow that:</p> <ol> <li>Proposes initial scenario drafts based on requirements</li> <li>Verifies that scenarios properly implement game theory structures</li> <li>Refines scenarios based on feedback</li> <li>Repeats the cycle until convergence or max iterations</li> </ol> <p></p>"},{"location":"reference/scenario_creation_graph/#architecture","title":"Architecture","text":"<p>The graph consists of the following components:</p>"},{"location":"reference/scenario_creation_graph/#state","title":"State","text":"<p>The state object (<code>ScenarioCreationState</code>) tracks: - Input requirements (game name, participants, jobs) - Working data (current scenario draft, feedback, iteration count) - Output (final scenario, convergence status)</p>"},{"location":"reference/scenario_creation_graph/#nodes","title":"Nodes","text":"<ol> <li>Propose Scenario (<code>propose_scenario</code>)</li> <li>Creates or refines scenario drafts based on game requirements</li> <li>Uses previous feedback for refinement in later iterations</li> <li> <p>Ensures proper JSON structure matching the game type</p> </li> <li> <p>Verify Scenario (<code>verify_scenario</code>)</p> </li> <li>Evaluates if the scenario properly implements the game theory structure</li> <li>Checks if the scenario mask is effective (players won't immediately recognize the game)</li> <li>Provides specific feedback for improvement</li> <li> <p>Determines if the scenario has converged (no more improvements needed)</p> </li> <li> <p>Finalize Scenario (<code>finalize_scenario</code>)</p> </li> <li>Saves the final scenario to a file</li> <li>Adds metadata and timestamps</li> <li>Returns the completed scenario</li> </ol>"},{"location":"reference/scenario_creation_graph/#edges-and-flow-control","title":"Edges and Flow Control","text":"<p>The graph uses conditional edges to determine the flow: - After verification, the <code>should_continue</code> function decides whether to:   - Refine the scenario (loop back to proposal)   - Finalize the scenario (proceed to saving)</p> <p>The process stops when either: - The scenario has converged (no more improvements needed) - Max iterations have been reached (default: 5)</p>"},{"location":"reference/scenario_creation_graph/#reliable-json-response-handling","title":"Reliable JSON Response Handling","text":"<p>The implementation uses OpenAI's structured JSON response feature to ensure reliable parsing:</p> <ol> <li>Automatic JSON Response Format: All LLM calls use <code>response_format={\"type\": \"json_object\"}</code> to ensure responses are valid JSON.</li> <li>Simplified Parsing: This eliminates the need for complex regex extraction from markdown code blocks.</li> <li>Error Handling: Even with JSON mode enabled, we still have fallback error handling for any unexpected issues.</li> </ol> <p>This approach makes the system more robust and reduces the likelihood of parsing errors or malformed scenarios.</p>"},{"location":"reference/scenario_creation_graph/#usage","title":"Usage","text":"<pre><code>from scenario_creation_graph import create_scenario\n\n# Create a Prisoner's Dilemma scenario\nscenario = create_scenario(\n    game_name=\"Prisoners_Dilemma\",\n    participants=[\"Alice\", \"Bob\"],\n    participant_jobs=[\"Software Developer\", \"Project Manager\"]\n)\n\n# Print the created scenario\nimport json\nprint(json.dumps(scenario, indent=2))\n</code></pre>"},{"location":"reference/scenario_creation_graph/#integration-with-existing-code","title":"Integration with Existing Code","text":"<p>This LangGraph implementation provides an alternative to the existing AutoGen-based scenario generation in <code>data_creation/create_scenario.py</code>. It offers several advantages:</p> <ol> <li>Iterative Refinement: Automatically improves scenarios through multiple iterations</li> <li>Quality Control: Verifies scenarios meet requirements before finalizing</li> <li>Transparency: Provides feedback at each step of the process</li> <li>Flexibility: Can be extended with additional verification steps or criteria</li> </ol>"},{"location":"reference/scenario_creation_graph/#extension-points","title":"Extension Points","text":"<p>The graph can be extended in several ways:</p> <ol> <li>Add more verification criteria in the <code>verify_scenario</code> function</li> <li>Implement human-in-the-loop feedback by adding a human verification node</li> <li>Add specialized nodes for different game types</li> <li>Integrate with other systems through additional output nodes </li> </ol>"},{"location":"reference/sequence_probability_vllm_hook/","title":"Sequence Probability vLLM Hook","text":""},{"location":"reference/sequence_probability_vllm_hook/#overview","title":"Overview","text":"<p>The Sequence Probability vLLM Hook is a tensor parallel-aware hook system for capturing and calculating sequence probabilities from vLLM language models. This hook intercepts the language model head output to capture logits and compute log probabilities for target sequences.</p>"},{"location":"reference/sequence_probability_vllm_hook/#key-features","title":"Key Features","text":"<ul> <li>Tensor Parallel Support: Automatically detects and handles tensor parallel configurations in vLLM</li> <li>Logit Aggregation: Properly aggregates logits across tensor parallel ranks for accurate probability calculation</li> <li>RPC Communication: Uses vLLM's collective RPC system for distributed hook management</li> <li>Comprehensive Metrics: Computes log probabilities, probabilities, and perplexity</li> <li>Clean State Management: Automatic state setup and cleanup for reliable operation</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#implementation-location","title":"Implementation Location","text":"<ul> <li>Main Class: <code>neuro_manipulation.repe.sequence_prob_vllm_hook.SequenceProbVLLMHook</code></li> <li>Documentation: <code>neuro_manipulation/repe/README_sequence_prob_vllm_hook.md</code></li> <li>Tests: <code>neuro_manipulation/repe/tests/test_sequence_prob_vllm_hook.py</code></li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#usage-example","title":"Usage Example","text":"<pre><code>from vllm import LLM\nfrom transformers import AutoTokenizer\nfrom neuro_manipulation.repe.sequence_prob_vllm_hook import SequenceProbVLLMHook\n\n# Initialize model and tokenizer\nmodel_name = \"meta-llama/Llama-3.1-8B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nllm = LLM(model=model_name, tensor_parallel_size=1)\n\n# Create sequence probability hook\nseq_prob_hook = SequenceProbVLLMHook(llm, tokenizer)\n\n# Calculate probabilities\nprompt = \"The capital of France is\"\ntarget_sequences = [\"Paris\", \"London\", \"Berlin\"]\nresults = seq_prob_hook.get_log_prob([prompt], target_sequences)\n\n# View results\nfor result in results:\n    print(f\"Sequence: '{result['sequence']}'\")\n    print(f\"Log Probability: {result['log_prob']:.4f}\")\n    print(f\"Probability: {result['prob']:.6f}\")\n    print(f\"Perplexity: {result['perplexity']:.4f}\")\n</code></pre>"},{"location":"reference/sequence_probability_vllm_hook/#architecture-components","title":"Architecture Components","text":""},{"location":"reference/sequence_probability_vllm_hook/#hook-function","title":"Hook Function","text":"<ul> <li><code>hook_fn_sequence_prob()</code>: Captures logits from language model head output</li> <li>Stores logits with rank information for tensor parallel aggregation</li> <li>Handles both single tensor and tuple outputs</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#rpc-functions","title":"RPC Functions","text":"<ul> <li><code>_register_lm_head_hook_rpc()</code>: Registers hooks on language model head across workers</li> <li><code>_set_sequence_prob_state_rpc()</code>: Sets state for sequence probability capture</li> <li><code>_reset_sequence_prob_state_rpc()</code>: Cleans up state after capture</li> <li><code>_get_captured_logits_rpc()</code>: Retrieves captured logits from workers</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#main-class-methods","title":"Main Class Methods","text":"<ul> <li><code>__init__()</code>: Initializes hook and registers on language model head</li> <li><code>get_log_prob()</code>: Main method for calculating sequence probabilities</li> <li><code>_aggregate_logits_across_ranks()</code>: Handles tensor parallel logit aggregation</li> <li><code>_calculate_sequence_probabilities()</code>: Computes final probability metrics</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#tensor-parallel-handling","title":"Tensor Parallel Handling","text":"<p>The hook automatically handles different tensor parallel configurations:</p> <ol> <li>Single Rank (TP=1): Uses logits directly from the single worker</li> <li>Multi Rank (TP&gt;1): Concatenates logits along vocabulary dimension from all ranks</li> </ol>"},{"location":"reference/sequence_probability_vllm_hook/#return-format","title":"Return Format","text":"<p>The <code>get_log_prob()</code> method returns a list of dictionaries, each containing:</p> <ul> <li><code>sequence</code>: The target sequence string</li> <li><code>log_prob</code>: Log probability of the sequence</li> <li><code>prob</code>: Probability of the sequence (exp(log_prob))</li> <li><code>perplexity</code>: Perplexity of the sequence (exp(-log_prob))</li> <li><code>num_tokens</code>: Number of tokens in the sequence</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#integration-with-neural-manipulation","title":"Integration with Neural Manipulation","text":"<p>This hook complements the existing neural manipulation capabilities:</p> <ul> <li>Works alongside <code>RepControlVLLMHook</code> for comprehensive model analysis</li> <li>Can be used to measure the effect of neural interventions on sequence probabilities</li> <li>Provides quantitative metrics for evaluating manipulation effectiveness</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Memory: Logits are stored temporarily during calculation</li> <li>Computation: Scales with sequence length and vocabulary size</li> <li>Communication: RPC overhead for tensor parallel setups</li> <li>GPU Memory: Ensure sufficient VRAM for model + logit storage</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#testing","title":"Testing","text":"<p>Comprehensive unit tests are provided covering:</p> <ul> <li>Hook function behavior with various inputs</li> <li>RPC function communication</li> <li>Tensor parallel logit aggregation</li> <li>Main class functionality and error handling</li> <li>Edge cases and error conditions</li> </ul> <p>Run tests with: <pre><code>cd neuro_manipulation/repe/tests\npython -m unittest test_sequence_prob_vllm_hook.py\n</code></pre></p>"},{"location":"reference/sequence_probability_vllm_hook/#related-documentation","title":"Related Documentation","text":"<ul> <li>vLLM Hook Implementation</li> <li>Model Layer Detector</li> <li>vLLM Compatibility</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#dependencies","title":"Dependencies","text":"<ul> <li>PyTorch</li> <li>vLLM</li> <li>Transformers</li> <li>NumPy</li> <li>Python 3.8+</li> </ul>"},{"location":"reference/sequence_probability_vllm_hook/#limitations","title":"Limitations","text":"<ul> <li>Currently supports only forward pass probability calculation</li> <li>Requires models with accessible language model heads</li> <li>Hook removal functionality is placeholder (manual cleanup required)</li> <li>Memory usage scales with vocabulary size for logit storage </li> </ul>"},{"location":"reference/statistical_engine/","title":"Statistical Engine","text":"<p>This module provides a unified framework for statistical analysis and visualization of behavioral data, particularly for experiments involving emotions, intensities, and categorical decisions (e.g., cooperation/defection in game theory). It supports both JSON and CSV data formats and produces both statistical summaries and publication-ready plots.</p>"},{"location":"reference/statistical_engine/#main-components","title":"Main Components","text":""},{"location":"reference/statistical_engine/#1-behavioranalyzer","title":"1. <code>BehaviorAnalyzer</code>","text":"<ul> <li>Purpose: Central class for loading data, performing statistical analysis, and structuring results.</li> <li>Key Methods:</li> <li><code>load_data(file_path)</code>: Loads data from JSON or CSV.</li> <li><code>analyze_data(data_source, output_dir=None)</code>: Main entry point for analysis. Handles both CSV and JSON input, computes statistics, and generates plots.</li> <li><code>_analyze_emotion_effects(df)</code>: Analyzes behavioral differences across emotions.</li> <li><code>_analyze_intensity_effects(df)</code>: Analyzes intensity effects within each emotion.</li> <li><code>_analyze_multiple_emotions(emotion_files)</code>: Handles multiple JSON files (one per emotion).</li> <li><code>_analyze_conditions(condition_counts)</code>: Core logic for statistical tests and pairwise comparisons.</li> <li><code>format_full_results(analysis_results)</code>: Adds human-readable text descriptions to results.</li> </ul>"},{"location":"reference/statistical_engine/#2-behaviorvisualizer","title":"2. <code>BehaviorVisualizer</code>","text":"<ul> <li>Purpose: Handles all plotting and visualization of analysis results.</li> <li>Key Methods:</li> <li><code>update_category_labels(categories)</code>: Sets up color mapping for categories.</li> <li><code>plot_results(results, output_path, title=None)</code>: Main plotting function, creates bar plots and p-value heatmaps.</li> <li>Internal methods for plotting rates, heatmaps, and raw counts.</li> </ul>"},{"location":"reference/statistical_engine/#3-statistical-tests","title":"3. Statistical Tests","text":"<ul> <li>Chi-square test and Fisher's exact test are used to assess differences in categorical behavior across conditions (emotions/intensities).</li> <li>Pairwise comparisons are performed between all pairs of conditions.</li> <li>Significance markers (<code>*</code>, <code>**</code>) are added based on p-value thresholds.</li> </ul>"},{"location":"reference/statistical_engine/#4-textual-summaries","title":"4. Textual Summaries","text":"<ul> <li>The module generates a detailed, human-readable summary of the statistical findings, including:</li> <li>Per-condition behavior rates</li> <li>Overall test results</li> <li>Pairwise comparison results</li> </ul>"},{"location":"reference/statistical_engine/#example-usage","title":"Example Usage","text":"<pre><code>from statistical_engine import BehaviorAnalyzer\n\nanalyzer = BehaviorAnalyzer()\nresults = analyzer.analyze_data('path/to/data.csv')\nprint(results['text_description'])\n</code></pre> <ul> <li>For JSON input (multiple files): <pre><code>emotion_files = {\n    'happy': 'data/happy.json',\n    'sad': 'data/sad.json',\n    # ...\n}\nresults = analyzer.analyze_data(emotion_files)\n</code></pre></li> </ul>"},{"location":"reference/statistical_engine/#output","title":"Output","text":"<ul> <li>Plots: Saved to the specified output directory (default: sibling 'plots' folder).</li> <li>Results: Dictionary with detailed statistics and a text summary.</li> </ul>"},{"location":"reference/statistical_engine/#dependencies","title":"Dependencies","text":"<ul> <li>numpy, pandas, scipy, matplotlib, seaborn</li> </ul>"},{"location":"reference/statistical_engine/#see-also","title":"See Also","text":"<ul> <li>statistical_engine.py </li> </ul>"},{"location":"reference/vllm_compatibility/","title":"vLLM Compatibility with Representation Engineering","text":""},{"location":"reference/vllm_compatibility/#problem-hidden-states-access-in-vllm","title":"Problem: Hidden States Access in vLLM","text":"<p>When using the <code>vllm.LLM</code> model for generating text, we encountered a compatibility issue with the representation engineering (RepE) pipeline, specifically <code>rep-reading</code>. The issue was that vLLM models do not expose hidden states in the same way that HuggingFace models do, which was required for the <code>rep-reading</code> pipeline to build emotion readers.</p> <p>The original implementation in <code>model_utils.py</code> was loading the model twice:</p> <ol> <li>First as a <code>vllm.LLM</code> instance for efficient generation</li> <li>Then as a <code>transformers.AutoModelForCausalLM</code> for accessing hidden states</li> </ol> <p>This approach worked but led to doubled VRAM usage, as the model was effectively loaded twice in GPU memory.</p>"},{"location":"reference/vllm_compatibility/#current-workaround-temporary-model-for-repe-further-development-planned","title":"Current Workaround: Temporary Model for RepE (Further Development Planned)","text":"<p>Note: This section describes our current approach to enable Representation Engineering with vLLM. We are actively exploring more integrated solutions, as outlined in the \"Future Improvements\" section below.</p> <p>Our solution keeps the primary vLLM model for generation but creates a temporary HuggingFace model only when needed for the representation reading step:</p> <ol> <li>We use the primary vLLM model for all generation tasks</li> <li>Only when building emotion readers (in <code>load_emotion_readers</code>), we:</li> <li>Create a temporary HuggingFace model with aggressive memory optimization</li> <li>Use it to extract the necessary hidden states information</li> <li>Delete the temporary model and clear CUDA cache to free memory</li> <li>Cache the results to avoid repeating this step in future runs</li> </ol> <p>This approach provides: - Memory efficiency - the temporary model is loaded with minimal memory footprint options - Performance - we keep the highly optimized vLLM for inference - Compatibility - we can still use the representation engineering techniques</p>"},{"location":"reference/vllm_compatibility/#implementation-details","title":"Implementation Details","text":"<p>The implementation applies several VRAM optimization techniques to the temporary model:</p> <pre><code>hf_model = AutoModelForCausalLM.from_pretrained(\n    config['model_name_or_path'], \n    torch_dtype=torch.float16,  # Use half precision\n    device_map=\"auto\",\n    token=True, \n    trust_remote_code=True,\n    max_memory={0: \"2GiB\"},     # Limit memory usage\n    offload_folder=\"offload_folder\",  # Enable weight offloading\n    offload_state_dict=True,    # Offload weights not in use\n    low_cpu_mem_usage=True      # Optimize CPU memory usage\n).eval()\n</code></pre> <p>After the emotion readers are built, we explicitly free the memory:</p> <pre><code># Clean up the temporary model to free memory\ndel hf_model\ntorch.cuda.empty_cache()\n</code></pre>"},{"location":"reference/vllm_compatibility/#future-improvements","title":"Future Improvements","text":"<p>For a more complete solution, we could:</p> <ol> <li>Implement a full <code>RepReadingVLLM</code> class that directly extracts hidden states from vLLM models without needing the temporary HuggingFace model.</li> <li>Add more robust caching for the emotion readers to avoid rebuilding them when the model is restarted.</li> <li>Investigate direct hooks into the vLLM model architecture to access hidden states in a more memory-efficient way. </li> </ol>"},{"location":"reference/vllm_hook_implementation/","title":"vLLM Hook Implementation for Representation Control","text":"<p>This document explains the <code>RepControlVLLMHook</code> class, designed to apply representation control techniques (specifically <code>reading_vec</code> for now) to models running within the vLLM framework by leveraging forward hooks and Remote Procedure Calls (RPC).</p>"},{"location":"reference/vllm_hook_implementation/#overview","title":"Overview","text":"<p>Instead of wrapping model layers (as in <code>rep_control_reading_vec.py</code>), this approach injects control by registering PyTorch forward hooks directly onto the target layers (or submodules like <code>mlp</code>, <code>self_attn</code>) of the model running on each vLLM worker process. This avoids modifying the model structure itself but relies on vLLM's <code>collective_rpc</code> mechanism to manage the hooks and their associated state.</p>"},{"location":"reference/vllm_hook_implementation/#how-it-works","title":"How it Works","text":"<ol> <li> <p>Initialization (<code>__init__</code>):</p> <ul> <li>Takes a vLLM <code>LLM</code> instance, tokenizer, target layer indices, the name of the block/module within the layer to hook (e.g., <code>\"decoder_block\"</code> for the layer's main output), and the control method (<code>\"reading_vec\"</code>).</li> <li>Uses <code>collective_rpc</code> to call <code>_register_hook_on_worker_rpc</code> on each worker.</li> <li><code>_register_hook_on_worker_rpc</code> finds the specified module (e.g., the Nth decoder layer) on the worker's copy of the model and registers the <code>hook_fn_rep_control</code> function as a forward hook.</li> <li>The hook initially does nothing, as its control state is not yet set.</li> </ul> </li> <li> <p>Generation (<code>__call__</code>):</p> <ul> <li>Takes prompts and optional control parameters (<code>activations</code>, <code>token_pos</code>, <code>masks</code>, <code>normalize</code>, <code>operator</code>).</li> <li>Set State: If <code>activations</code> (a dictionary mapping layer indices to control tensors) are provided, it calls <code>_set_controller_state_on_worker_rpc</code> via <code>collective_rpc</code>.<ul> <li>This RPC function finds the target module on the worker and attaches a <code>_rep_control_state</code> attribute to it. This attribute holds the control tensor, mask, operator function, and other parameters needed by the hook.</li> </ul> </li> <li>Run Inference: It calls the standard <code>model.generate()</code> method.<ul> <li>During the forward pass on each worker, when execution reaches a hooked module, the <code>hook_fn_rep_control</code> is triggered.</li> <li>The hook checks if <code>_rep_control_state</code> exists on the module.</li> <li>If the state exists, the hook retrieves the control parameters (controller tensor, mask, operator, etc.) and applies the modification logic (e.g., adding the controller vector to the module's output) before returning the modified output.</li> <li>If no state exists, the hook simply returns the original output.</li> </ul> </li> <li>Reset State: After generation finishes (in a <code>finally</code> block to ensure cleanup), it calls <code>_reset_controller_state_on_worker_rpc</code> via <code>collective_rpc</code>.<ul> <li>This RPC function finds the target module on the worker and deletes the <code>_rep_control_state</code> attribute, ensuring subsequent unrelated inference calls are not affected.</li> </ul> </li> </ul> </li> <li> <p>Hook Function (<code>hook_fn_rep_control</code>):</p> <ul> <li>This function contains the core logic for applying the representation control modification, similar to the logic within <code>WrappedBlock.forward</code> in <code>rep_control_reading_vec.py</code>.</li> <li>It handles accessing the correct output tensor (even if the module returns a tuple), applying masks, handling token positions, performing normalization, and using the specified operator (e.g., linear combination).</li> </ul> </li> </ol>"},{"location":"reference/vllm_hook_implementation/#advantages","title":"Advantages","text":"<ul> <li>No Model Monkey-Patching: Doesn't require modifying the vLLM model's layer structure directly.</li> <li>Leverages vLLM Infrastructure: Uses <code>collective_rpc</code> for distributed state management.</li> </ul>"},{"location":"reference/vllm_hook_implementation/#disadvantagesconsiderations","title":"Disadvantages/Considerations","text":"<ul> <li>RPC Overhead: Sending control state via RPC for every controlled generation call might introduce some overhead compared to having the logic permanently wrapped in the layer.</li> <li>State Management Complexity: Relies on correctly setting and resetting state via RPC. Errors in RPC or state management could lead to inconsistent behavior.</li> <li>Hook Limitations: Hooks might interact unexpectedly with vLLM's internal optimizations or execution graph. <code>enforce_eager=True</code> might be necessary when initializing the vLLM <code>LLM</code> object.</li> <li>Hook Removal: Properly removing hooks registered via RPC requires careful handle management, which is currently implemented conceptually but might need refinement.</li> </ul>"},{"location":"reference/vllm_hook_implementation/#usage-example","title":"Usage Example","text":"<p>For an example demonstrating initialization, baseline generation, and controlled generation, please refer to the <code>if __name__ == \"__main__\":</code> block in the <code>neuro_manipulation/repe/rep_control_vllm_hook.py</code> script. </p>"}]}